<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>本科课程 - 系列 - 暮瞻</title>
        <link>https://blog.ralvines.top/series/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/</link>
        <description>本科课程 - 系列 - 暮瞻</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>ralvine@163.com (Ralvine)</managingEditor>
            <webMaster>ralvine@163.com (Ralvine)</webMaster><lastBuildDate>Mon, 30 Oct 2023 20:20:40 &#43;0800</lastBuildDate><atom:link href="https://blog.ralvines.top/series/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/" rel="self" type="application/rss+xml" /><item>
    <title>当代文学前沿问题研究</title>
    <link>https://blog.ralvines.top/wxqy/</link>
    <pubDate>Mon, 30 Oct 2023 20:20:40 &#43;0800</pubDate><author>
                        <name>Ralvine</name><uri>https://blog.ralvines.top/about.md</uri><email>ralvine@163.com</email></author><guid>https://blog.ralvines.top/wxqy/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="https://z1.ax1x.com/2023/10/23/piAW5eH.png" referrerpolicy="no-referrer">
            </div><p><div class="details admonition quote open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-quote-right fa-fw"></i>课程信息<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">🎓 数学科学学院<br>
🕙 2023-2024 秋冬<br>
🧑‍🏫 毕惟红<br>
📝 50%读书报告，10%考勤，10%编程，30%两次展示</div>
        </div>
    </div> true</p>
<p>!!! quote &quot;&quot;
- 🎓 数学科学学院
- 🕙 2020-2021 春夏
- 🧑‍🏫 吴秀明，陈力君
- 📝 签到，讨论课发言，展示，期末考试</p>
<h2 id="参考" class="headerLink">
    <a href="#%e5%8f%82%e8%80%83" class="header-mark"></a>参考</h2><h2 id="大纲" class="headerLink">
    <a href="#%e5%a4%a7%e7%ba%b2" class="header-mark"></a>大纲</h2><p>!!! note &quot;&quot;
- <strong>CH1.</strong> 导论及背景介绍
- <strong>CH2.</strong> 《青春之歌》解读
- <strong>CH3.</strong> 金庸武侠小说及其定位
- <strong>CH4.</strong> 金庸武侠小说思想艺术特点
- <strong>CH5.</strong> 影片《新龙门客栈》
- <strong>CH6.</strong> “后金庸”时代的武侠小说
- <strong>CH7.</strong> 诺贝尔文学奖与中国当代文学
- <strong>CH8.</strong> 纪实文学热与领袖传记文学
- <strong>CH9.</strong> “80后”文学创作（一）
- <strong>CH10.</strong> “80后”文学创作（二）</p>
<h2 id="学习笔记" class="headerLink">
    <a href="#%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0" class="header-mark"></a>学习笔记</h2><h3 id="名词解释" class="headerLink">
    <a href="#%e5%90%8d%e8%af%8d%e8%a7%a3%e9%87%8a" class="header-mark"></a>名词解释</h3><ul>
<li>
<p>**三红一创，青山保林：**指的是对新中国十七年小说的坚持政治艺术统一的高度概括，也是十七年红色经典小说的高度集中。毛泽东文艺思想《在延安文艺座谈会上的讲话》在1949年后逐渐成为指导全国文学艺术工作的唯一正确的文艺思想。这时期的文艺路线是：文学为政治服务，文学为工农兵服务。文学别无选择的充当了生活教科书的任务。</p>
</li>
<li>
<p>**范式：**范式从本质上讲是一种理论体系、理论框架。在该体系框架之内的该范式的理论、法则、定律都被人们普遍接受。</p>
</li>
<li>
<p>**撰论：**金庸社论？</p>
</li>
<li>
<p>**超验：**超出一切可能的经验之上，超越时间、空间等存在形式，不能用因果、属性、存在、不存在等范畴进行思考的东西。强调直觉，超越感觉理性。</p>
</li>
<li>
<p>**暴力美学：**暴力美学主要是在感官上，使暴力以美学的方式呈现，诗意的画面，甚至幻想中的镜头来表现人性暴力面和暴力行为。观赏者本身往往惊叹于艺术化的表现形式，无法对内容产生具体的不舒适感。</p>
</li>
<li>
<p>伟人生活化模式、政治人格化模式、社会心理化模式。</p>
</li>
<li>
<p>**社会学意义的80后：**家庭结构、伦理观念、经济结构、人与物关系、当代中国历史和技术环境的变化。</p>
</li>
<li>
<p><strong>80后作家：</strong>(2010年前80后作家群概念扩展而来) 指1980年后出生的一些作家写手，互联网写作环境对他们影响深刻，创作初期主要以同龄人为阅读对象。萌芽作家和非萌芽作家。体制外写作和第二渠道发行。娱乐原则和交换原则下的大众传媒的扩张。</p>
</li>
<li>
<p>**第二渠道：**二渠道是指除主渠道(传统国营书店如新华书店等)以外的其他发行渠道，主要是民营的图书批发和零售通道。还有“特殊渠道”指网上书店、系统发行等新兴发行渠道。</p>
</li>
<li>
<p>**唯理性教学模式：**将充满人性之美和生活趣味的语文变成机械枯燥的应试训练。“唯理性教学模式”纵横贯穿于语文教学领域。这种模式崇尚抽象、概括、提炼、崇尚逻辑思维能力，却忽略情感、意志和审美情趣的介入；重视将一切语文知识加以解构和量化，却忽略了从文本和人本的整体角度高屋建瓴地培养学生的语文能力；重视语文学科的互补性。</p>
</li>
<li>
<p>**50后到90后：**建构大历史，解构，生活，虚拟，无视社会-自我，群体-小我，大众-私我，世界-亲我。</p>
</li>
<li>
<p>**80后风格：**现代生活，速度生活，都市风情、酒吧咖啡商场职场等文化、国际化视角、叛逆与自我立场。</p>
</li>
<li>
<p>**耽美文学：**耽美一词最早是出现在日本近代文学中，为反对“自然主义”文学而呈现的另一种文学写作风格。有“耽美派”，它的最初本意是反对以暴露人性的丑恶面为主的自然主义，并想找出官能美、陶醉其中追求文学的意义。引申为代指一切美形的男性，以及男性与男性之间不涉及繁殖的恋爱感情，最后更发展为同性恋漫画的代称之一。</p>
</li>
<li>
<p>**同人小说：**指的是利用原有的漫画、动画、小说、影视作品中的人物角色、故事情节或背景设定等元素进行的二次创作小说。同人小说一般是以网络小说为载体，近年来，伴随体育人物、娱乐人物、政治人物等社会人物的高密集度曝光，同人小说中的真人同人小说也逐渐兴起。</p>
</li>
<li>
<p>**韩寒：**创作原则现实主义、文学反映人生的传统文学观念、讽喻，批判、叛逆、个性化表达，社会游荡者流浪者傻傻的同行者纯情女友人物形象，松散离奇骑士情结滑稽人生经历，反讽夸大双关荒诞。</p>
</li>
<li>
<p>**80后电影：**青春成长题材，情感与成长阵痛，独立电影影像表达，梦幻暴力场面，较强的影响语言把握运用能力。</p>
</li>
<li>
<p>**生态文学：**关于生态问题的文学，具有生态维度的文学，反思和批判生态思想和观念表达，基于当下和现实生态状况的文学作品，具有生态标准或尺度的文学创作和批评。揭示问题，试图摆脱危机。</p>
</li>
<li>
<p>**生态危机：**整体而非局部的生态系统出现问题，被破坏。人类文明历史是一部人类与自然的关系史</p>
</li>
<li>
<p>**人类中心主义：**又译“人类中心论”，是以人类为事物的中心的学说。同其他文化观念一样，人类中心主义的观念也具有历史发展的连续性和间断性，这一概念曾在三个意义上使用人类中心主义总是作为一种价值和价值尺度而被采用的，把人类的利益作为价值原点和道德评价的依据，有且只有人类才是价值判断的主体。</p>
</li>
<li>
<p>**土地伦理：**土地伦理是环境伦理的视角之一，是由奥尔多·利奥波德在他的《沙乡年鉴》一书中首次倡导的。其中他写道，需要一种“新的伦理”，“一种处理人与土地，以及人与在土地上生长的动物和植物之间的伦理观”。在他那个时代，美国林业局的主流观念从创立者吉福德·平肖开始，就是追求经济利益的和功利主义的，而利奥波德则主张一种“生态学”的态度(这个词由芝加哥大学的亨利·钱德勒·考尔斯于20世纪初在对印地安那沙丘的研究中提出，利奥波德是该术语最早的推广者之一)。资源保护主义在更偏向人类中心主义的资源管理范式中获得了它的首要地位，而与此同时，利奥波德的著作和启发与约翰·缪尔一起引发了环境主义的发展。</p>
</li>
<li>
<p>**生态文学价值取向：**否定强权、人类中心主义重构人和自然关系，同情关怀弱势种群探寻非人类种群精神世界，坚持开放评判姿态倡导土地伦理以孩童或他者视角，强调人类责任探寻生态危机原因预测世界未来。</p>
</li>
<li>
<p>**景别：**景别是指由于在焦距一定时，摄影机与被摄体的距离不同，而造成被摄体在摄影机录像器中所呈现出的范围大小的区别。景别的划分，一般可分为五种，由近至远分别为特写(指人体肩部以上)、近景(指人体胸部以上)、中景(指人体膝部以上)、全景(人体的全部和周围部分环境)、远景(被摄体所处环境)。</p>
</li>
<li>
<p>**镜头语言：**镜头语言就是用镜头像语言一样去表达我们的意思，我们通常可经由摄影机所拍摄出来的画面看出拍摄者的意图，因为可从它拍摄的主题及画面的变化，去感受拍摄者透过镜头所要表达的内容。</p>
</li>
<li>
<p>**女性意识与南方文化：**江南经济发展带来新的时尚，经济发展带来坊刻文化繁荣，文字图画共存产生新欣赏口味满足情感需求</p>
</li>
<li>
<p>**女性作家群：**闺塾师，妇女诗社。</p>
</li>
<li>
<p>**女性文学规模形成：**情趣化和美感合理运用冲破科场文化限制，产生新文类新空间。至此成为被拘囿和局限了空间和观念的充满通融和争执的存在。</p>
</li>
<li>
<p>**传统女性文学：**零星存在的才女创作，文以载道成为中国文学核心价值，教育资源性别倾斜。特点：女性只能通过男性角色完成心愿才能展示，女性意识表现不能超越社会价值观念，女性意识只能委婉曲折地得以传达传统和新女性文学的审美表达、文类、视角区别：国事政事到家事情事，优美与壮美，亚文类诗-词，史传-小说。</p>
</li>
<li>
<p>**亚文类：**从属于&hellip;&hellip;</p>
</li>
<li>
<p>科场：科举场所·五四女性文学：批家庭家族文化反抗父权表达爱情个人反抗夫权，女教师学生形象，如萧红、丁玲、白薇。</p>
</li>
<li>
<p>**三四十年代女性文学：**彼时女性普遍生存现实的书写、生命意识和精神世界的探索，如丁玲、萧红、张爱玲</p>
</li>
</ul>
<h3 id="讨论课发言" class="headerLink">
    <a href="#%e8%ae%a8%e8%ae%ba%e8%af%be%e5%8f%91%e8%a8%80" class="header-mark"></a>讨论课发言</h3><h4 id="3月11日---时代与经典的关系" class="headerLink">
    <a href="#3%e6%9c%8811%e6%97%a5---%e6%97%b6%e4%bb%a3%e4%b8%8e%e7%bb%8f%e5%85%b8%e7%9a%84%e5%85%b3%e7%b3%bb" class="header-mark"></a>3月11日 - 时代与经典的关系</h4><p>我以为，作为裹挟于时代浪潮之中的个体，我们很难不受到一定时期社会经济基础、主流意识形态及生活方式的影响，也自然难以超脱于一定的历史桎梏。</p>
<p>譬如春秋战国时期松散的权力结构和相对适足的经济基础营造出一段思想多元的历史浪潮，诸子百家各自收揽大批追随者。而在秦代之后的君主专制中央集权时期，帝王及其朝廷所采取的治理模式很大程度上影响到社会的主流思潮，因而，生前郁郁不得志的孔子也难以预料到罢黜百家后的中原王朝将在千年的历史长河中将儒家经典奉为圭臬。</p>
<p>诗歌、书法形式的变革亦如是，而伴随着市井文化和较为稳定社会环境下的新兴商贸体系的形成、社会生活的日益丰富和各阶层群体利益的复杂化，明清文人又将主流视角从曾经强调主观情调与高洁理想的抒情范式转向了更多强调矛盾与故事性的长篇小说与戏曲。</p>
<p>而对于《青春之歌》来说，我认为它的现实意义在于其以爱情主线展现出时代变迁中的社会主流意识形态演化脉络及沉浮其中的小人物的精神蜕变，而前者恰恰属于对青春主题所作出的极富那个年代历史语境下的价值解构。</p>
<p>如前所述，随着时代的变革，传统社会形态和价值取向的消解，自然优先作用于文艺创作的土壤。建国前期，传统氏族结构的崩溃和产缘纽带的建构加速歧化社会群体生活理念之于以高级知识分子代表的精英与广泛的劳动大众的落差。而五四以降，特别是以左翼革命为主线的元叙事成为中国社会意识形态的中流砥柱之后，民国早期以引入、吸收、传播乃至照搬西方启蒙思想的文人群体与“农村包围城市”的无产阶级觉醒产生了精英与平民视角的对立。在新民主主义革命者在天安门城楼宣布胜利的历史帷幕之下，主流话语体系自然如毛泽东文艺思想所展现——强调“人民性”与“革命性”，对“高高在上”教化愚昧无知大众的旧知识分子群体赋予了批判和改造的内在使命，而这恰恰寓于彼时文学作品的内核之中。正如林道静爱情主线下的身份转变，从资产阶级知识分子到无产阶级革命者，从同余永泽相处时之于革命较为纯粹的浪漫主义和理想主义到最后彻底脱离旧体系束缚、成为更为独立坚毅的女性共产主义战士，极具彼时时代特征的宏大思想理念作为政治隐喻内化于情感叙事之中，对于当代的我们理解这一历史阶段具有生动的意义。</p>
<h4 id="3月18日---金庸小说的意义与影响" class="headerLink">
    <a href="#3%e6%9c%8818%e6%97%a5---%e9%87%91%e5%ba%b8%e5%b0%8f%e8%af%b4%e7%9a%84%e6%84%8f%e4%b9%89%e4%b8%8e%e5%bd%b1%e5%93%8d" class="header-mark"></a>3月18日 - 金庸小说的意义与影响</h4><p>作为00后，金庸的武侠作品在我们这一代人的青年时段中似乎正在悄然式微，相较文学本身，留给我们的更多的往往是电视上《射雕英雄传》《天龙八部》的浮光掠影。因此，当我们提到金庸武侠小说的影响时，必然绕不开它和它贯穿的整个文学时代给现在的我们留下了什么。
首先，金庸的武侠小说开启了此类文学作品的全新范式。在当今许多新兴网络文学作品中，那些英雄、玄幻色彩背后，往往蕴含着金庸时代武侠小说的叙事风格和情节架构。古代传统社会的背景下，具有现代主义特征的爱情、仁善元素包裹着其特有的畅快淋漓之词藻，将打斗场面描绘得无比生动。阅读时，我能感受到它与读者偌大想象空间的完美契合。
其次，金庸的武侠小说影响了一代人，特别是在世界观的形成层面。“侠之大者，为国为民。”相较于《水浒》等古代经典小说，金庸文学作品更突出救死扶伤、保家卫国、同情弱者的人文关怀，这与他创作时的时代背景是密不可分的。它不仅仅强调传统的忠义兄弟情，更展现了人性的复杂一面。即便是江湖英雄，也有脆弱的一面；如此仗义的侠客，也总有种种缺点和软肋。而善恶亦不是纯粹的二元对立，大量“圆形人物”的塑造往往透露出老庄辩证哲学的转化思想。正所谓“有人的地方就有江湖”，金庸作品似乎善于解构正义与邪恶对立背后的复杂利益因素，在人情世故中将丰富的感性成分融入于前者。</p>
<h4 id="5月27日---80后文学的时代风格" class="headerLink">
    <a href="#5%e6%9c%8827%e6%97%a5---80%e5%90%8e%e6%96%87%e5%ad%a6%e7%9a%84%e6%97%b6%e4%bb%a3%e9%a3%8e%e6%a0%bc" class="header-mark"></a>5月27日 - 80后文学的时代风格</h4><p>或许因为代际差异，我个人对80后作家的文学作品并不是很熟悉。就80后文学作品的风格、选材及作者审美诉求的变化，正如此前数周大家所呈现和讨论，“计划生育”、改革开放、外来文化冲击、互联网萌芽、去政治化等等要素建构了这一代人的集体意识形态。这一点也在伤痕文学中有所体现。</p>
<p>80后作家们的视角更趋向“小我”，在各种新鲜事物或文化的强烈冲击之下，80后有一种置于承前启后时代的独特孤独感，一方面受到社会传统领域的束缚牵制，另一方面到处孕育着多元的机会。我想这注定是彷徨、探索着的一代，具体来说，《上海公园》中同学聚会上大量对白的表达所呼应的悲伤、压抑的意象，正是这一代人冲动而迷茫的缩影。那些旧日同窗有的谈吐中时刻夹杂着外语，眼神里显现出无尽的却又有些幼稚的渴望与追求感；有的弹奏吉他，沉醉于自我的表达，也奋力于谋求出路……总而言之，是对宏大叙事的回避，是对小我情态的捕捉，贯穿其中、处处可见的则是都市、西方文化与懵懂青年的朦胧交错。</p>
<h4 id="6月10日---生态文学叙事" class="headerLink">
    <a href="#6%e6%9c%8810%e6%97%a5---%e7%94%9f%e6%80%81%e6%96%87%e5%ad%a6%e5%8f%99%e4%ba%8b" class="header-mark"></a>6月10日 - 生态文学叙事</h4><p>在我看来，冷峻而真实的场景建构、人性与生命脆弱性的呈现似乎是《可可西里》代表的这一类生态影片的叙事共性。在生命的禁区，善恶界限愈发模糊、道德伦理与法律秩序渐隐，刘栋和日泰的突然死亡深刻地揭示了人类在自然面前的渺小，而日泰不得不卖皮子与马占林复杂的人物形象体现着上述生存遇到威胁的情境下现实之于个体的矛盾。在某种意义上说，在当下人与自然的和谐共生本质上仍然是人类基于自身主观利益的诉求，当自然反噬人类的侵略行为或是人类惊觉自然资源的稀缺性时，其才展现出可悲的保护意识；人类的理性往往屈从于求生的基础本能，这是一种妥协与无奈，也振聋发聩地促使我们去反思，我们究竟需要追求一种怎样的同自然生态的交互反馈。</p>
<p>**课后随想：**本次讨论课的主题是生态文学，并比较分析了《狼图腾》和《怀念狼》两部作品。命题的核心如老师在周二课上提出，生态文学是“退步的文学”，是人类文学发展进程中的一次“回眸”。要理解生态文学，自然需要聚焦于其意识产生的基础，即人类发展中“进步的模式”同“文明的模式”之间存在的必然的矛盾及人改造、征服自然过程中受到反噬从而产生的问题。而从文学角度讲，生态文学所要反思的本质上是社会生态、精神生态的问题，探讨人类自身在相应认知上存在的问题。由此而言，生态文学无疑是对客观现实的一种进步反映，也是人类在工业化浪潮下环保意识、天人合一意识的觉醒。然而，这一时期的生态文学又有一种人类生活模式的保守化倾向，毕竟在工业化对自然显著的、触目惊心的破坏现实之中，文学创作者们又难以找到一条清晰的解决路径，从而容易陷入到“返璞归真”的思维陷阱之中。无论如何，发展的问题恐怕只能用发展解决，我认为人类应当顺应生产力发展的方向，通过科技的进步为人与自然和谐共生提供强力的正反馈。</p>
<h4 id="6月17日---文艺作品中的女性角色" class="headerLink">
    <a href="#6%e6%9c%8817%e6%97%a5---%e6%96%87%e8%89%ba%e4%bd%9c%e5%93%81%e4%b8%ad%e7%9a%84%e5%a5%b3%e6%80%a7%e8%a7%92%e8%89%b2" class="header-mark"></a>6月17日 - 文艺作品中的女性角色</h4><p>对第三小组的第二个问题，我倾向于认为这是一个伪命题。</p>
<p>当代对女性群体的关注与女性这一群体概念的强化本身是平权主义的分支，也就是消除传统桎梏尚未完全解体的性别歧视与刻板印象。然而，刚才当我们谈论这些性别标签下的群体特质时，却恰恰是在潜移默化地在制造刻板印象。</p>
<p>但是它为什么存在？课堂上有同学提到的铁娘子撒切尔夫人，这一套“强硬”形象难道就是男性固有的特质吗？我更相信这是一种文化惯性的结果，是传统男性主导地位导致的。比如过去的领导人绝大部分都是男性，既有文质彬彬儒雅随和者、也有政治强人、强硬做派者，凡此种种，其实本质上是群体的历史记忆让在过去占有主导地位的男性垄断了绝大部分特质的标签。</p>
<p>而对于所谓的性别视角下作家的思维特质，我认为这其实属于个体化的范畴，而非由性别因素所决定。譬如同为男性作家，木心和刘慈欣拥有着迥然不同的创作风格与叙事模式。这些实质上是作者在职业、文化氛围、生活环境、宗教、思维模式乃至意识形态上的差别，而思维模式等要素本身很少受到性别本身的影响。
值得一提的是，从生物学上说，男女之间的基因演化最终是趋同的，男性与女性不同基因对其认知与行为模式差异的影响远远小于外在环境等因素。</p>
<p>个人认为，当代女权主义中的反抗精神仿佛是一种“弱势者的群体皈依，抱团取暖”的表现，这自然有一定的道理，然而也不能忽视事实上掌握话语权的核心并非性别。如当代西方普遍的种族问题，往往掩盖了根本的阶级矛盾；又比如80后的标签，是这一代人在改革开放浪潮、独生子女政策等集体记忆和社会背景下交互下的产物，而不能简单归咎于在80年代出生这一基本定义。</p>
<p>至于性别话语权的垄断确实存在，但在当代更多地是表现在刻板印象之中，比如所谓的男性阳刚女性阴柔，以及女性生理特质带来的部分劣势之中，比如由于生育、产假、体力问题导致的女性在职场中的弱势地位，不过不要忽视此种差异是双向的，正如随着社会发展，尽管简单的体力工作男性占据了主体优势，却也有一些专属于女性的职业存在。</p>
<p>课上谈论女性悲剧形象时，就有不少同学指出去除性别标签后，悲剧的形象仍然有着共性。而女性文学中普遍提到的封建社会下如翠翠独守闺房与祥林嫂式的悲剧，前者是女性在生活上的依附现实，后者则是生产上的性别依附。</p>
<p>总体来说，此种话语权的不匹配在现代社会下是在不断消解的。我比较认同平权问题用辩证唯物主义那套理论框架来阐释，当代妇女解放与女性意识的觉醒本身就是在后工业化时代，社会生产关系中的性别差异被机器的运用所逐渐抹平，女性大规模参与到现代生产活动之中的结果。</p>
<p>男女的差异事实上主要仍然体现在基因等生理要素之上，当代很多性别不平等现象相较封建时代已经得到了很大的进步，相反，很多问题是文化惯性、历史遗留，这在生产力落后的农村和欠发达地区仍有呈现。我们知道即便是在原始社会也存在着母系社会，所谓的父权社会很大程度上是战争频繁的农耕时代男性由于生理上具有的体力优势的社会经济基础所衍生出的一套伦理体系。而这些差异已经被证明是能够随着科技进步而式微的，因此，对于“女性的悲剧结局能否避免”这一论题，我相信这将随着时代的发展获得肯定的答案。</p>]]></description>
</item><item>
    <title>数学前沿专题讨论：遗传算法和统计学习方法</title>
    <link>https://blog.ralvines.top/qianyan/</link>
    <pubDate>Mon, 30 Oct 2023 20:20:40 &#43;0800</pubDate><author>
                        <name>Ralvine</name><uri>https://blog.ralvines.top/about.md</uri><email>ralvine@163.com</email></author><guid>https://blog.ralvines.top/qianyan/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="https://z1.ax1x.com/2023/11/01/pinHqnH.png" referrerpolicy="no-referrer">
            </div><div class="details admonition quote open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-quote-right fa-fw"></i>课程信息<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">🎓 数学科学学院<br>
🕙 2023-2024 秋冬<br>
🧑‍🏫 毕惟红<br>
📝 50%读书报告，10%考勤，10%编程，30%两次展示</div>
        </div>
    </div>
<h2 id="背景" class="headerLink">
    <a href="#%e8%83%8c%e6%99%af" class="header-mark"></a>背景</h2><ol>
<li>浙大 计算数学</li>
<li>研究生</li>
</ol>
<ul>
<li>数字模拟 投影法求曲面面积</li>
<li>随机数生成 数值代数 多元非线性方程组求解</li>
</ul>
<p><strong>研究方向</strong></p>
<ol>
<li>图像处理</li>
</ol>
<ul>
<li>图像分割 图像识别</li>
<li>图像加密 做的比较好</li>
</ul>
<ol start="2">
<li>语义识别</li>
</ol>
<ul>
<li>三维点式数据（无人驾驶、激光雷达）</li>
</ul>
<ol start="3">
<li>社区发现</li>
</ol>
<ul>
<li>复杂网络</li>
<li>拟牛顿</li>
</ul>
<h2 id="遗传算法" class="headerLink">
    <a href="#%e9%81%97%e4%bc%a0%e7%ae%97%e6%b3%95" class="header-mark"></a>遗传算法</h2><h2 id="统计学习方法" class="headerLink">
    <a href="#%e7%bb%9f%e8%ae%a1%e5%ad%a6%e4%b9%a0%e6%96%b9%e6%b3%95" class="header-mark"></a>统计学习方法</h2><h2 id="首次展示knn" class="headerLink">
    <a href="#%e9%a6%96%e6%ac%a1%e5%b1%95%e7%a4%baknn" class="header-mark"></a>首次展示：kNN</h2><h3 id="分类问题1" class="headerLink">
    <a href="#%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%981" class="header-mark"></a>分类问题<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></h3><ul>
<li>
<p>一种监督学习问题，旨在对数据分类</p>
</li>
<li>
<p>将输入数据映射到预定义的类别或标签</p>
</li>
<li>
<p>从已知的训练数据中学习一个分类模型，然后将该模型应用于新的、未知的数据，以预测其所属的类别</p>
</li>
<li>
<p>垃圾邮件过滤、金融风险评估</p>
</li>
<li>
<p>医学诊断、生物信息学</p>
</li>
<li>
<p>情感分析、客户分类</p>
</li>
<li>
<p>图像识别</p>
</li>
</ul>
<h3 id="knn模型构建" class="headerLink">
    <a href="#knn%e6%a8%a1%e5%9e%8b%e6%9e%84%e5%bb%ba" class="header-mark"></a>kNN模型构建</h3><h4 id="提出2" class="headerLink">
    <a href="#%e6%8f%90%e5%87%ba2" class="header-mark"></a>提出<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></h4><p>$$T={(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)}$$
$$y_i\in\mathcal{Y}={c_1,c_2,\cdots,c_K}$$
$$y=\text{arg}\max\limits_{c_j} \sum\limits_{x_i\in N_k(x)} I(y_i=c_j)$$</p>
<ul>
<li>
<p>输入：特征向量（空间点）</p>
</li>
<li>
<p>输出：类别（可以取多类）</p>
</li>
<li>
<p>已标注的训练集</p>
</li>
<li>
<p>预测：多数表决（“近朱者赤” ）</p>
</li>
<li>
<p>不具有显式的学习过程</p>
</li>
</ul>
<p><strong>适用范围</strong></p>
<ul>
<li>数值型和标称型<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></li>
</ul>
<p><strong>优点</strong><sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup><sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup></p>
<ol>
<li>直观、非参数化</li>
<li>对异常值不敏感</li>
<li>支持多类别</li>
</ol>
<p><strong>缺点</strong><sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup></p>
<ol>
<li>时间复杂度高</li>
<li>存储成本高</li>
<li>“维度灾难”和数据不平衡</li>
</ol>
<h4 id="构建流程" class="headerLink">
    <a href="#%e6%9e%84%e5%bb%ba%e6%b5%81%e7%a8%8b" class="header-mark"></a>构建流程</h4><p>给定距离度量，k值与决策规则 [输入训练集T]</p>
<ol>
<li>在训练集 T 中找出与 x 最邻近的 k 个点，涵盖这 个点的 x 的邻域记作 $N_k(a)$</li>
<li>在 $N_k(a)$ 中根据分类决策规则决定 x 的类别 y</li>
</ol>
<p><strong>基本要素</strong></p>
<ol>
<li>k 值选择</li>
<li>距离度量</li>
<li>决策规则</li>
</ol>
<p>特殊情况：最近邻（k=1）</p>
<p><figure><a class="lightgallery" href="https://z1.ax1x.com/2023/11/01/piuKE6K.png" title="特征空间划分" data-thumbnail="https://z1.ax1x.com/2023/11/01/piuKE6K.png">
        
    </a></figure></p>
<h3 id="模型要素" class="headerLink">
    <a href="#%e6%a8%a1%e5%9e%8b%e8%a6%81%e7%b4%a0" class="header-mark"></a>模型要素</h3><h4 id="k-值选择" class="headerLink">
    <a href="#k-%e5%80%bc%e9%80%89%e6%8b%a9" class="header-mark"></a>k 值选择</h4><table>
<thead>
<tr>
<th>k值</th>
<th>偏小</th>
<th>偏大</th>
</tr>
</thead>
<tbody>
<tr>
<td>近似误差</td>
<td>减小</td>
<td>增大</td>
</tr>
<tr>
<td>估计误差</td>
<td>增大</td>
<td>减小</td>
</tr>
</tbody>
</table>
<p>交叉验证以提高泛化性能。<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup></p>
<h4 id="距离度量9" class="headerLink">
    <a href="#%e8%b7%9d%e7%a6%bb%e5%ba%a6%e9%87%8f9" class="header-mark"></a>距离度量<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup></h4><p>对于
$$x_i=(x_i^{(1)}, x_i^{(2)}, \cdots, x_i^{(n)})$$</p>
<ul>
<li>$L_p$ 距离
$$L_p(x_i,x_j)=(\sum\limits_{l=1}^n |x_i^{(l)}-x_j^{(l)}|^p)^{1/p}$$</li>
<li>欧氏距离
$$L_2(x_i,x_j)=(\sum\limits_{l=1}^n |x_i^{(l)}-x_j^{(l)}|^2)^{1/2}$$</li>
<li>曼哈顿距离
$$L_1(x_i,x_j)=\sum\limits_{l=1}^n |x_i^{(l)}-x_j^{(l)}|$$</li>
<li>$L_\infty$ 距离
$$L_\infty (x_i,x_j)=(\max\limits_l |x_i^{(l)}-x_j^{(l)}|$$</li>
</ul>
<h4 id="决策规则" class="headerLink">
    <a href="#%e5%86%b3%e7%ad%96%e8%a7%84%e5%88%99" class="header-mark"></a>决策规则</h4><p><strong>多数表决</strong>
由输入实例的 k 个邻近的训练实例中的多数类决定输入实例的类。</p>
<ul>
<li>分类函数
$$f:\mathbb{R}^n\rightarrow {c_1,c_2,\cdots,c_K}$$</li>
<li>误分类概率
$$P(Y\ne f(X))=1-P(Y=f(X))$$</li>
<li>等价于风险经验最小化
$$\frac{1}{k}\sum\limits_{x_i\in N_k(x)} I(y_i\ne c_j)=1-\frac{1}{k}\sum\limits_{x_i\in N_k(x)} I(y_i=c_j)$$</li>
</ul>
<h3 id="模型预测" class="headerLink">
    <a href="#%e6%a8%a1%e5%9e%8b%e9%a2%84%e6%b5%8b" class="header-mark"></a>模型预测</h3><h4 id="预测流程" class="headerLink">
    <a href="#%e9%a2%84%e6%b5%8b%e6%b5%81%e7%a8%8b" class="header-mark"></a>预测流程</h4><p>首先引入最简单的思路：线性扫描的方法。</p>
<ol>
<li>对未知类别的数据集中的每个点：</li>
</ol>
<ul>
<li>计算已知类别数据集众多点与当前点之间的距离；</li>
<li>按照距离递增次序排序。</li>
</ul>
<ol start="2">
<li>选取与当前点距离最小的k个点：</li>
</ol>
<ul>
<li>选定前k个点所在类别的出现频率</li>
<li>返回前k个点出现频率最高的类别作为当前点的预测分类</li>
</ul>
<ol start="3">
<li>重复步骤，完成对所有点的预测分类</li>
</ol>
<h4 id="python实现" class="headerLink">
    <a href="#python%e5%ae%9e%e7%8e%b0" class="header-mark"></a>Python实现</h4><p><figure><a class="lightgallery" href="https://z1.ax1x.com/2023/11/01/piuKkSx.png" title="kNN算法流程可视化" data-thumbnail="https://z1.ax1x.com/2023/11/01/piuKkSx.png">
        
    </a></figure></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">KNN</span><span class="p">:</span> 
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">euclidean_distance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x1</span> <span class="o">-</span> <span class="n">x2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">distances</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">euclidean_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_train</span><span class="p">)</span> <span class="k">for</span> <span class="n">x_train</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">k_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">distances</span><span class="p">)[:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">k_nearest_labels</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">k_indices</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">most_common</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">k_nearest_labels</span><span class="p">)</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">most_common</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 一个简单的例子：</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span> <span class="o">=</span> <span class="n">KNN</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">predictions</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="改进" class="headerLink">
    <a href="#%e6%94%b9%e8%bf%9b" class="header-mark"></a>改进</h3><h4 id="主要挑战" class="headerLink">
    <a href="#%e4%b8%bb%e8%a6%81%e6%8c%91%e6%88%98" class="header-mark"></a>主要挑战</h4><ol>
<li>前置处理：特征的选择</li>
<li>模型</li>
</ol>
<ul>
<li>合适的度量函数</li>
<li>合适的K值</li>
<li>降低训练和预测的复杂度</li>
</ul>
<h4 id="kd树" class="headerLink">
    <a href="#kd%e6%a0%91" class="header-mark"></a>kd树</h4><p>一种二叉树数据结构，用于优化搜索算法。</p>
<p><strong>优势：</strong></p>
<ol>
<li>降低搜索维度</li>
<li>提高搜索效率</li>
<li>更少的存储需求</li>
<li>支持范围搜索</li>
</ol>
<p>可能因数据的特定分布而表现不佳。<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup></p>
<h5 id="构造11" class="headerLink">
    <a href="#%e6%9e%84%e9%80%a011" class="header-mark"></a>构造<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup></h5><ol>
<li>构造根结点，使根结点对应于 k 维空间中包含所有实例点的超矩形区域。</li>
<li>递归（生成子结点）：</li>
</ol>
<ul>
<li>选择坐标轴和切分点，确定一个超平面</li>
<li>将当前超矩形区域切分为左右两个子区域</li>
<li>直到子区域内没有实例时终止。</li>
</ul>
<ol start="3">
<li>实例保存在相应的结点上。</li>
</ol>
<p><strong>如何选择：</strong></p>
<ul>
<li>空间切分参照：坐标轴</li>
<li>切分点的选择：中位数</li>
</ul>
<p><figure><a class="lightgallery" href="https://z1.ax1x.com/2023/11/01/piuKif1.png" title="kd树的构造" data-thumbnail="https://z1.ax1x.com/2023/11/01/piuKif1.png">
        
    </a></figure></p>
<h5 id="搜索" class="headerLink">
    <a href="#%e6%90%9c%e7%b4%a2" class="header-mark"></a>搜索</h5><p><figure><a class="lightgallery" href="https://z1.ax1x.com/2023/11/01/piuKAl6.png" title="kd树的搜索" data-thumbnail="https://z1.ax1x.com/2023/11/01/piuKAl6.png">
        
    </a></figure></p>
<h5 id="算法" class="headerLink">
    <a href="#%e7%ae%97%e6%b3%95" class="header-mark"></a>算法</h5><p>[输入] 已构造的 kd 树，目标点 x;</p>
<p>[输出] x 的 k 近邻。</p>
<ol>
<li>在 kd 树中找出包含目标点 x 的叶结点：从根结点出发，递归地向下访问 kd 树。若目标点 x 当前维的坐标小于切分点的坐标，则移动到左子结点，否则移动到右子结点，直到子结点为叶结点为止。</li>
<li>构建“当前 k 近邻点集”，将该叶结点插入“当前 k 近邻点集”，并计算该结点到目标点 x 的距离。</li>
<li>递归地向上回退，在每个结点进行以下操作:</li>
</ol>
<ul>
<li>如果“当前 k 近邻点集”的元素数量 &lt; k，则将该结点插入“当前 k 近邻点集”，并计算该结点到目标点 x 的距离;</li>
<li>如果“当前 k 近邻点集”的元素数量 = k，但该结点到目标点 x 的距离小于“当前 k 近邻点集”中最远 点到目标点 x 的距离，则将该结点插入“当前 k 近邻点集”，并删除原先的最远点。</li>
<li>检查另一子结点对应的区域是否与以目标点 x 为球心、以目标点 x 与“当前 k 近邻点集”中最远点的距离为半径的超球体相交。 如果相交，可能在另一个子结点对应的区域内存在距离目标点更近的点，移动到另一个子结点，接着，递归地进行 k 近邻搜索; 如果不相交，向上回退。</li>
</ul>
<ol start="4">
<li>当回退到根结点时，搜索结束(若此时“当前 k 近邻点集”中的元素不足 k 个，则需要访问另一半树的结点)。</li>
<li>最后的“当前 k 近邻点集”中的 k 个点即为 x 的 k 近邻点。</li>
</ol>
<h5 id="python实现-1" class="headerLink">
    <a href="#python%e5%ae%9e%e7%8e%b0-1" class="header-mark"></a>Python实现</h5><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Node</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">left</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">right</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">val</span> <span class="o">=</span> <span class="n">data</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">left</span> <span class="o">=</span> <span class="n">left</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">right</span> <span class="o">=</span> <span class="n">right</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">KdTree</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">create_Tree</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">depth</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="n">dataset</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="n">mid_index</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">        <span class="n">axis</span> <span class="o">=</span> <span class="n">depth</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span>
</span></span><span class="line"><span class="cl">        <span class="n">sort_dataset</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="n">axis</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">        <span class="n">mid_data</span> <span class="o">=</span> <span class="n">sort_dataset</span><span class="p">[</span><span class="n">mid_index</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">cur_node</span> <span class="o">=</span> <span class="n">Node</span><span class="p">(</span><span class="n">mid_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">left_data</span> <span class="o">=</span> <span class="n">sort_dataset</span><span class="p">[:</span><span class="n">mid_index</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">right_data</span> <span class="o">=</span> <span class="n">sort_dataset</span><span class="p">[</span><span class="n">mid_index</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>
</span></span><span class="line"><span class="cl">        <span class="n">cur_node</span><span class="o">.</span><span class="n">left</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_Tree</span><span class="p">(</span><span class="n">left_data</span><span class="p">,</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">cur_node</span><span class="o">.</span><span class="n">right</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_Tree</span><span class="p">(</span><span class="n">right_data</span><span class="p">,</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">cur_node</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tree</span><span class="p">,</span> <span class="n">new_data</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">near_point</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">near_val</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">dfs</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">depth</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="ow">not</span> <span class="n">node</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">return</span>
</span></span><span class="line"><span class="cl">            <span class="n">axis</span> <span class="o">=</span> <span class="n">depth</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">new_data</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">node</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="n">axis</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">                <span class="n">dfs</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">left</span><span class="p">,</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">dfs</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">right</span><span class="p">,</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="n">new_data</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">val</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">near_val</span> <span class="ow">or</span> <span class="n">dist</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">near_val</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">near_val</span> <span class="o">=</span> <span class="n">dist</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">near_point</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">val</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">new_data</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">-</span> <span class="n">node</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="n">axis</span><span class="p">])</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">near_val</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="n">new_data</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">node</span><span class="o">.</span><span class="n">val</span><span class="p">[</span><span class="n">axis</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">                    <span class="n">dfs</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">right</span><span class="p">,</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">                <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="n">dfs</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">left</span><span class="p">,</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">dfs</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">near_point</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">distance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">point_1</span><span class="p">,</span> <span class="n">point_2</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">res</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">res</span> <span class="o">+=</span> <span class="p">(</span><span class="n">point_1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="n">point_2</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">res</span> <span class="o">**</span> <span class="mf">0.5</span>
</span></span><span class="line"><span class="cl"><span class="n">data_set</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mi">9</span><span class="p">,</span><span class="mi">6</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">7</span><span class="p">],[</span><span class="mi">8</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl"><span class="n">new_data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">k</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_set</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">kd_tree</span> <span class="o">=</span> <span class="n">KdTree</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">our_tree</span> <span class="o">=</span> <span class="n">kd_tree</span><span class="o">.</span><span class="n">create_Tree</span><span class="p">(</span><span class="n">data_set</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">predict</span> <span class="o">=</span> <span class="n">kd_tree</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">our_tree</span><span class="p">,</span> <span class="n">new_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="马氏距离" class="headerLink">
    <a href="#%e9%a9%ac%e6%b0%8f%e8%b7%9d%e7%a6%bb" class="header-mark"></a>马氏距离</h4><p>由P.C. Mahalanobis提出；基于样本分布的一种距离测量。</p>
<ul>
<li>考虑特征之间的相关性</li>
<li>对数据的缩放不敏感</li>
<li>考虑协方差结构</li>
<li>适用于异常值和噪声数据<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup></li>
</ul>
<p>广泛用于分类和聚类分析。</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>垃圾邮件过滤：自动将电子邮件分为垃圾邮件和非垃圾邮件。<br>
医学诊断：基于患者的症状数据来诊断疾病或预测病人的疾病风险。<br>
金融风险评估：根据客户的财务和信用记录来评估客户的信用风险。<br>
情感分析：根据文本数据中的情感内容对文本进行情感分类，如积极、消极或中性。<br>
图像识别：对图像进行分类，例如识别数字、物体或人脸等。<br>
生物信息学：基因序列分类，如预测蛋白质功能或基因表达模式。<br>
客户分类：根据客户的行为和偏好将客户分成不同的市场细分。&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>KNN算法于1948年由Cover和Hart提出。<br>
存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每个数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，只选择样本数据集中前k个最相似的数据。k一般不大于20，最后，选择k个中出现次数最多的分类，作为新数据的分类。<br>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>数值型数据是指具有数量意义的数据，可以进行数学运算和比较。这种数据通常表示为数字，例如年龄、温度、身高等。在机器学习中，数值型数据常用于回归分析和连续变量的预测。标称型数据则是指无序分类的数据，其中每个值代表一个类别而没有数量意义。标称型数据通常表示为符号或字符串，例如血型、性别、品种等。在机器学习中，标称型数据通常用于分类问题，其中算法需要将输入数据映射到预定义的类别或标签。<br>
k最近邻算法 (kNN) 适用于处理这两种类型的数据。对于数值型数据，它可以基于数值之间的距离进行分类；对于标称型数据，它可以根据邻近样本的标签进行投票，并将测试样本分类为获得最多投票的类别。因此，kNN 算法对于这两种数据类型都有较好的适用性。<br>
还有其他类型：<br>
顺序型数据：顺序型数据是一种具有顺序或等级关系的数据类型，其中数据值之间存在某种顺序关系，但没有明确的数值差异。例如，学历等级（如小学、初中、高中、大学等）可以被视为顺序型数据。<br>
时间序列数据：时间序列数据是按照时间顺序排列的数据集合，通常是在一系列连续时间点上收集的数据。例如，股票价格、天气数据、经济指标等都属于时间序列数据。<br>
区间型数据：区间型数据是指数据值表示某个范围内的值，而不是特定的数值。这种数据类型通常用于表示测量的范围。例如，温度范围、年龄段等可以被视为区间型数据。<br>
比率型数据：比率型数据是具有固定比例关系的数据类型，其中数据之间存在明确的比率关系。比率型数据具有绝对零点，可以进行比较和数学运算。例如，长度、重量、时间间隔等都属于比率型数据。<br>
文本数据：文本数据是指以自然语言形式表示的数据，通常包含语句、段落或文档。处理文本数据通常需要使用自然语言处理技术来提取、转换和分析文本信息。<br>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>老师反馈：这里的表述并不严谨，模型需要通过交叉验证来确认参数 k&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>简单直观，非参数化：kNN 是一种非参数化方法，不对数据的分布做任何假设。因此，在处理复杂的数据集和未知的数据分布时，它通常具有很好的适应性。<br>
对异常值鲁棒：kNN 对异常值比较鲁棒，因为它基于周围数据点的多数投票来确定分类，可以减少异常值对结果的影响。<br>
适应多类别问题：kNN 能够很好地适应多类别分类问题，因为它可以通过投票的方式来确定一个实例所属的类别。<br>
但是对高维数据的处理效率较低，需要大量的存储空间和计算时间；在数据不平衡或噪声较多的情况下，它可能会产生较差的分类结果。<br>&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>计算成本高：kNN 算法需要计算每个测试点与所有训练点之间的距离，因此在处理大规模数据集时，计算成本会变得非常高。<br>
存储成本高：除了计算成本高外，kNN 算法还需要存储整个训练集，这对于大规模数据集来说会占用大量的存储空间。<br>
维度灾难：随着数据维度的增加，kNN 算法的性能可能会下降，因为在高维空间中，数据点之间的距离变得更加稀疏，导致算法的效率降低。<br>
数据不平衡问题：在处理数据不平衡或噪声较多的数据集时，kNN 算法可能会受到数据分布的影响，从而导致分类性能下降。<br>&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>近似误差是指模型用于近似真实关系的误差，通常表示模型与真实值之间的差异。<br>
估计误差是指使用样本数据估计整体数据集特征时产生的误差。在 kNN 中，估计误差通常与样本的选择和样本的分布有关。<br>
K值的减小：模型变得复杂，容易发生过拟合。相当于用较小的邻域中的训练实例进行预测，只有与输入实例较近的(相似的)训练实例才会对预测结果起作用，对噪声敏感，即预测结果会对近邻的实例点非常敏感。如果邻近的实例点恰巧是噪声，预测就会出错。换句话说，k 值的减小就意味着整体模型变得复杂，容易发生过拟合。<br>
K值的增大：就意味着整体的模型变得简单.产生更平滑的决策边界，但可能会忽略数据的局部特征。这时与输入实例较远的(不相似的)训练实例也会对预测起作用，使预测发生错误。k 值的增大就意味着整体的模型变得简单。<br>
k 值一般取一个比较小的数值。通常采用交叉验证法来选取最优的k 值。具体可以取部分训练集作为测试集，在不同取值条件下观察最优值。&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>特征空间中两个实例点的距离是两个实例点相似程度的反映。k 近邻模型的特征空间一般是 n 维实数向量空间 $R^n$，使用的距离是欧氏距离，但也可以是其他距离，如更一般的 $L_p$ 距离或 Minkowski 距离。&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p>实现 k 近邻法时，主要考虑的问题是如何对训练数据进行快速 k 近邻搜索。这点在特征空间的维数大及训练数据容量大时尤其必要。k 近邻法最简单的实现方法是线性扫描。这时要计算输入实例与每一个训练实例的距离。当训练集很大时，计算非常耗时，这种方法是不可行的。为了提高k 近邻搜索的效率，可以考虑使用特殊的结构存储训练数据，以减少计算距离的次数。具体方法很多，下面介绍其中的 kd 树方法。<br>
使用 kd 树相比直接计算方法的主要好处在于它可以有效地减少计算量。kd 树是一种二叉树数据结构，它可以用于优化搜索算法，特别是在高维空间中。<br>
以下是 kd 树相对于直接计算方法的一些优势：<br>
降低搜索维度：kd 树能够将搜索范围缩小到与搜索点最近的局部区域，从而避免不必要的计算。<br>
提高搜索效率：在具有大量数据点的高维空间中，kd 树可以更快地定位最近邻居，因为它可以避免对所有数据点进行逐一比较。<br>
更少的存储需求：相对于直接计算方法，kd 树通常需要更少的存储空间，因为它可以通过二叉树结构有效地组织数据。<br>
支持范围搜索：除了最近邻搜索之外，kd 树还可以很容易地扩展到支持范围搜索，以查找在给定半径内的所有邻居。<br>
尽管 kd 树具有这些优势，但它可能会因数据的特定分布而表现不佳。例如，在存在大量密集聚集数据点的区域，kd 树的性能可能会下降。因此，在实际应用中，应该根据数据集的特点选择合适的算法来进行近邻搜索。&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p>kd 树是一种对 k 维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。kd 树是二叉树，表示对 k 维空间的一个划分。构造 kd 树相当于不断地用垂直于坐标轴的超平面将k 维空间切分，构成一系列的飞 维超矩形区域。kd树的每个结点对应于一个k 维超矩形区域。<br>
构造 kd 树的方法如下:构造根结点，使根结点对应于 k 维空间中包含所有实例点的超矩形区域:通过下面的递归方法，不断地对 k 维空间进行切分，生成子结点。在超矩形区域(结点)上选择一个坐标轴和在此坐标轴上的一个切分点，确定一个超平面，这个超平面通过选定的切分点并垂直于选定的坐标轴，将当前超矩形区域切分为左右两个子区域（子结点）；这时，实例被分到两个子区域。这个过程直到子区域内没有实例时终止（终止时的结点为叶结点）。在此过程中，将实例保存在相应的结点上。<br>
平衡树：使用中位数作为划分点可以保证树的相对平衡，避免出现极端情况下的不平衡树结构，从而使得搜索效率总体比较高，但未必最优。考虑一些离群点。&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p>考虑特征之间的相关性：马氏距离能够考虑数据特征之间的相关性，而欧氏距离只考虑各个维度之间的直线距离。这意味着马氏距离在具有相关特征的数据集上能够提供更加准确的距离度量。<br>
对数据的缩放不敏感：在某些情况下，数据的不同特征可能具有不同的度量单位或尺度。马氏距离能够对数据的缩放不敏感，因此可以更好地处理这种情况，而欧氏距离可能受到数据尺度的影响。<br>
考虑协方差结构：马氏距离考虑了数据的协方差结构，因此可以更好地捕捉数据特征之间的线性关系。这使得马氏距离在处理多元正态分布数据时能够提供更加准确的距离度量。<br>
适用于异常值和噪声数据：马氏距离能够对异常值和噪声数据具有更好的鲁棒性，因为它考虑了数据的协方差结构，可以减少这些异常值对距离度量的影响。&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>]]></description>
</item><item>
    <title>政治经济学</title>
    <link>https://blog.ralvines.top/zzjjx/</link>
    <pubDate>Tue, 04 Jul 2023 20:20:40 &#43;0800</pubDate><author>
                        <name>Ralvine</name><uri>https://blog.ralvines.top/about.md</uri><email>ralvine@163.com</email></author><guid>https://blog.ralvines.top/zzjjx/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="https://z1.ax1x.com/2023/10/23/piA8qxO.png" referrerpolicy="no-referrer">
            </div><h2 id="思考题-1" class="headerLink">
    <a href="#%e6%80%9d%e8%80%83%e9%a2%98-1" class="header-mark"></a>思考题 1</h2><div class="details admonition tip open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-lightbulb fa-fw"></i>选题<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">制度创新与中国式现代化。</div>
        </div>
    </div>
<p>从卸下旧社会三座大山到迈向现代化强国建设新征程，中国在站起来、富起来、强起来的历史脉络中找到了一条自主适定、以制度创新一以贯之的独特现代化道路，以思想理念引领，并从其战略与战术中分别派生完备架构与动态规制的实践，宣告了历史终结论和西方单线路径依赖史观的破产。</p>
<p>战略上<strong>知行交互</strong>。始终以理论指引实践，实事求是，统筹人文地理、阶层产业等规模和结构的特有国情，在社会主义原则下顺应先进生产力方向，通过顶层设计明晰目标，把握民族复兴国家富强的总体方向，规范了现代化的中心任务、原则和本质要求。此外，以实践导向反馈理论创新，在改革试验和制度化积累的循环中，逐渐建构起从粗放到集约、创新协调绿色开放共享的现代化发展模式，服务于最广大人民根本利益，在各个阶段锚定顺应现实规律的着力点。</p>
<p>战术上<strong>要素协同</strong>。完善各领域联系，将现代化贯穿于五位一体布局之中，让生产方式的广义主体相适配，注重有效市场和有为政府、城市群拓与乡村振兴、执政党和政府、公有经济与私有资本等要素的权衡和配合，在执政党总揽全局、协调各方的宏观尺度下，以政府报告、五年规划等常态规划推动策略创新，如在节奏快、容错强的领域引入社会资本，合理使用金融工具在适度的贫富差距下分配各主体在生产中的地位，以共同富裕和国际竞争旨归推动结构性改革，拉动制造产业等供给端升级，带动需求端的扩张，统筹国内循环和同国际双循环的协同发展。</p>
<p>空间上，<strong>架构完备</strong>是根本。中国式现代化有效发挥一切积极因素，实践探索和制度化相得益彰，打通了规划、执行、监督的链路。既覆盖农业工业服务业三大产业和政府企业两大主体，统筹地区、城乡、收入差异，又践行全过程人民民主和协商民主，团结各阶层有序参与建设，使生产力和生产关系、经济基础和上层建筑的基本矛盾在战略战术的迭代中更加系统完备。同上述规划环节的科学民主性对偶，地区试点和举国体制的交织、央地人事财各类权力的分工，则构成了中国式现代化高效执行力和创新力的根基。</p>
<p>时间上，<strong>规策动态</strong>是保障。从韬光养晦到奋发有为、双轨制到市场决定资源配置、从自立自主到融入国际，从以农哺工到乡村振兴，在大时代的振荡中，中国式现代化下的内政外交、政治经济方方面面都围绕着主要矛盾和国际情势，抓住机遇，保持历史主动，因势而动、顺势而为，不断推进方针与制度的革新，打破路径依赖，换道超车，审视未来。</p>
<p>总之，中国式现代化是社会主义性质、具有中国特色的现代化，摒弃了西方物质与资本导向、两极分化、对外扩张的老路，科学而富有活力。</p>
<p style="text-align:right">（984字）</p>
<h2 id="思考题-26" class="headerLink">
    <a href="#%e6%80%9d%e8%80%83%e9%a2%98-26" class="header-mark"></a>思考题 2<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></h2><div class="details admonition tip open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-lightbulb fa-fw"></i>选题<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">从劳动分工和异化劳动等视角，探究“大国大城”论与“美丽乡村”论之间的辩证统一关系。</div>
        </div>
    </div>
<p>“大国大城”论与“美丽乡村”论映射出了社会经济发展之于二元的城市和乡村取向模式的路径差异。前者渴望通过规模扩张与分工细化获得更优效率收益，后者考量劳动异化和剩余价值，指出乡村百业兴旺模式以效率代价兼顾劳动者的公平。</p>
<p>发展大城市和乡村振兴在形式上<strong>存在对立</strong>。城市化意味着生产资料的集中化，人才积聚、资本汇集建构起庞大规模且高度分工协作的产业网络。然而，在市场决定资源配置和私有制资本普遍存在的当代，社会生产过程是产生使用价值的劳动过程和派生剩余价值的价值增殖过程的统一，劳动创造价值，但剩余价值往往被占据支配地位者褫夺。高度社会分工下，规模且系统的工作被分解为简单的流程，个体沦为重复工作的机器，而生产的社会化和所有制的私有进一步割裂了劳动者与它的劳动成果，后者被货币化统一衡量、以商品形式在市场上高速流通，个体的价值被矮化为一套单一维度标准体系下的投入与产出过程，劳动者变为可被交易的生产要素。分工严重阻碍了人的自由全面发展，作为集体的城市得到了更高的收益，但作为个体的劳动者却缺省了应有的公平。</p>
<p>作为多体系统的乡村是我国粮食安全和国民经济发展的压舱石。以农业为基础的乡村百业虽然参与同城市的商品流通和社会化生产，但因其自然条件和所有制结构表征出相对独立的样态。相对分散的土地、资本和人口使农民大多自有生产要素和居住空间，从农林牧副渔五业并举到旅游等新兴产业的蓬勃交融并不改变乡村分散生产模式和农民为自己打工的生产关系，但这种颇具自给自足小农经济色彩的低分工模式也不可避免的牺牲了一定的效率。</p>
<p>两种路径的执理内核在于对于社会发展中效率与公平、短期与长期效益的分歧。现代化建设应当统筹兼顾做大蛋糕和分好蛋糕，国家经济社会的发展也离不开时间尺度下的利弊权衡。</p>
<p>发展大城市和乡村振兴在现代化进程中又是<strong>统一</strong>的。城乡区别本质上是经济基础即生产力和生产关系上的差异，表现为形式上的二元和载体的内生一致性。形式上，城乡具有相对独立的产业经济体系，然而同时，它们又是置于全国经济格局下相互联系的地域主体。</p>
<p>城乡融合是乡村振兴和城市化的耦合。通过城乡要素自由流动，引导三类产业深度融合，带动乡村产业振兴，规模工业和资本密集型的高新产业则为城市赋以更佳的效能，辅以城乡居民基本权益与服务均等化，乡村为产业资本集中的城市工业提供产能和劳动力过剩危机的“软着陆”蓄水池，城市则为乡村提供更强的三产流动性和工业品，从而实现城市的短期效率与乡村的长期公平的优势互补、共同繁荣。</p>
<p style="text-align:right">（996字）</p>
<h2 id="读书报告" class="headerLink">
    <a href="#%e8%af%bb%e4%b9%a6%e6%8a%a5%e5%91%8a" class="header-mark"></a>读书报告</h2><p>现代化的代价</p>
<p>——《八次危机》读书报告</p>
<blockquote>
<p>“两个互不否定”的历史见证了中国经济举世瞩目的成就。那么，代价是什么呢？</p>
</blockquote>
<p>作为在“三农”领域深耕多年的乡建派学者，温铁军教授的《八次危机》一书深刻阐释了新中国经济社会发展的辉煌成果背后，所经历的八次“经济危机”，同时探讨了乡村对缓冲共和国工业化进程中多次危机的重要贡献。本书还剖析了宏观微观双重视角下的中国式现代化历程，提出了成本转嫁论，即城乡二元结构体制下的“三农”承载着城市资本危机的“软着陆”代价。</p>
<p>去意识形态化是本书的精髓。从序言开始，温教授便深入浅出地解构了当代经济学体系中西方话语体系的固有定势，并基于马克思主义政治经济学和几十年的本土研究成果阐述了数个振聋发聩的核心观点，以历史唯物主义精神力图还原被利益集团所扭曲的厚重历史。揆诸当下，百年未有之大变局下，各种黑天鹅、灰犀牛事件交织发生，国际竞争格局日益复杂，我国经济发展也到了新的攻坚期，书中对乡村振兴和城乡融合发展的思路对时下具有深刻的借鉴意义。</p>
<p>“工业化的背后必然有成本转嫁。”工业革命以来，工业化是各国现代化建设的主线，工业实力奠定了国家实力的基础，而工业化必然伴随着资本的原始积累。和中国类似的诸多后发独立国家在融入资本主义的世界生产体系后，为了获得建设的大量资金，不得不以牺牲部分主权来引入外部资本，而这种模式成为了后殖民主义时代老牌工业国家剥削它们的高明手段，在此类路径依赖中，发达国家得以将经济发展的成本与危机在开放市场的情境下转嫁给缺乏消化危机制度成本的后者，使得各国之间的马太效应更佳显著。</p>
<p>书中花费了大量篇幅分析新中国前三十年的工业化建设模式，从中可以清晰地认识到奠基我国重工业基础的代价是工农“剪刀差”和“全盘苏化”带来的部分权益之牺牲。通过举国动员和全国人民的辛苦建设，我们用农矿产品换来了开启工业化大门的最核心、最底层的支持，但也因为路径依赖在外交环境恶化后，在财政危机下迫不得已开展上山下乡运动。在这里，农村第一次展现了其化解城市危机的重要价值，为缺乏资本和技术的城市与供给过剩的知识分子提供了短暂的庇护所，“劳动力的集中投入成功地代替了长期绝对稀缺的资金，农村由其内生的稳定性成功地承接并化解了城市的危机”，深刻分析了当时我国的经济基础、上层建筑，特别是城乡生产关系对经济发展的影响。</p>
<p>城乡二元体制也是本书重点着墨的话题。温教授一针见血地指出我国“地方化”资源资本发展的客观事实。在很长时间内，地方的高度分权是央地财政分配体系的重要特征，“政府公司化”自1958年放权地方以来延续至今，使得政府成为经济活动中的另一重要引擎。而城乡二元结构带来的割裂，为工农产品“剪刀差”提供了社会条件。改革开放以来，广袤乡村的农民在非市场化制度下平均分配到无风险的资产，又将风险收益拱手让读于企业家和沿海发达地区的政府，他们为我国迈入社会主义市场经济体制亦做出了不可磨灭的贡献。“新中国成立后，农民仅通过这三种方式为国家建设积累资金就至少达到17.3万亿元”，可见“三农”在我国发展历程中的贡献如此之重。</p>
<p>回望当下，随着对外开放的进一步深入和金融资本同经济社会更深层的嵌合，为了防范化解重大危机，实现可持续发展，解决好“三农”问题成为时代的新命题。新世纪以来，资本相较于产业不断过剩，旧的经济发展主义向更为绿色、科学的精细化模式转变。进入免除了农业税的“后税费时代”，农业人口结构的老龄化所引发的劳动力稀缺危机弱化了农村的社会调节功能，如何以生态文明建设引领农村新型工业化和城镇化，将山水资源以货币形式自我资本化，将广袤农村的自然要素锚定于更具流通性的价值度量，推动城乡产业融合发展、促进商品流通和农村内需延扩，都是更为实质性的问题。而在知识阶层再一次渐趋过剩的今天，除了城市服务业蓄水池之外，如何进一步发挥好农村在解决产能和劳动力匹配性问题的作用，也是令人值得深思的问题。</p>
<h2 id="横向叙事与资本主义符号幻觉" class="headerLink">
    <a href="#%e6%a8%aa%e5%90%91%e5%8f%99%e4%ba%8b%e4%b8%8e%e8%b5%84%e6%9c%ac%e4%b8%bb%e4%b9%89%e7%ac%a6%e5%8f%b7%e5%b9%bb%e8%a7%89" class="header-mark"></a>横向叙事与资本主义符号幻觉</h2><h3 id="资本主义存续的逻辑" class="headerLink">
    <a href="#%e8%b5%84%e6%9c%ac%e4%b8%bb%e4%b9%89%e5%ad%98%e7%bb%ad%e7%9a%84%e9%80%bb%e8%be%91" class="header-mark"></a>资本主义存续的逻辑</h3><p>自工业革命以降，以雇佣劳动为基础的资本主义生产方式通过技术革新和市场扩张，推动了生产力的跃迁式进步，然而，生产社会化与生产资料私有制之间的固有矛盾使得以剥削为本质的资本主义阶级社会不断震荡于贫富分化、生产过剩的复合危机。不同于封建社会，在其本身无法容纳的新经济基础还未出现前，经历了从自由到国家垄断阶段的资本主义统治机器为了消弭资产阶级和无产阶级的内在矛盾，<font color=red><b>建构了一系列旨在分化无产阶级的横向叙事与实现隐性奴役的精巧符号机制</b></font><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>，本文试图揭露当代资本主义以放大人民内部矛盾方式维护其合法性和稳定性的原因和具体手段，以批判其压迫本质。</p>
<p>作为一种基于商品生产和货币交换的异化社会形态，资本主义的寄生于被广泛标的的一切价值客体之中。人既以劳动力形式被出卖，又沦为再生产环节的消费奴隶，从而矮化为资本增殖的直接手段，即便是掌握生产资料的资产阶级，也不过是资本的人格化主体。<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>于是，资本主义结构性地运作于私有制基础上的两大基本阶级与社会再生产在形式与内容上的耦合过程，<font color=red><b>实现资本增殖和调和阶级矛盾便成为其存续的现实张力，前者是目的，后者则是手段的总和。</b></font></p>
<h3 id="合法性建构" class="headerLink">
    <a href="#%e5%90%88%e6%b3%95%e6%80%a7%e5%bb%ba%e6%9e%84" class="header-mark"></a>合法性建构</h3><p>实现自身增殖是资本的天然使命。<sup id="fnref1:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>社会化生产下，资产阶级通过生产资料资本化后的周期性运作，不仅需要通过剥削无产阶级以获得剩余价值，也要求大量的无产阶级作为消费者参与到被资本广泛度量的商品的价值实现过程中去，因此资本主义制度不仅派生了受压迫的潜在掘墓人，也源源不断地筛取了劳动力这一社会再生产中无可替代的燃料，从而最大限度的榨取了剩余价值，奠基了资本主义的规模与效率导向。</p>
<p>为了合理化资本主义的剥削机制、维护统治，资产阶级在深层逻辑上建构起一套以自洽的叙事，<font color=red><b>即在物质层面以商品经济和消费社会为载体的行为准则限定被统治阶级的作用范畴，同时在思想上编织一套以分化无产阶级为手段的叙事话语。</b></font>以消费为标志的符号社会<sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>为叙事的完备性提供了客观基础，而性别、地域矛盾的转嫁又更好地标签化这些消费的主体，进一步加深了资本主义再生产的坚实基础。</p>
<h4 id="符号崇拜" class="headerLink">
    <a href="#%e7%ac%a6%e5%8f%b7%e5%b4%87%e6%8b%9c" class="header-mark"></a>符号崇拜</h4><p>基于工业化、市场化的资本主义现代化路径，资本将物质度量为可供交易的消费品，而商品符号<sup id="fnref2:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>在资本规则的集体叙事下约束了使用者的行为，将无产阶级也置于一套无法脱离的生产生活体系之中，人性的自然需求被嫁接于社会性的消费浪潮之内，而交易本身隐去了资本主义的结构本质，物质的欲望反而成为了他们辩护资本主义生产方式的内驱动力，由此，阶级的对立被掩盖，表象的价值均衡与实在的利益剥削在后者的集体意识形态中得以错置。</p>
<p>资本主义的生产模式决定了商品化社会下，人作为劳动力被卷入庞大的生产结构之中沦为消耗品，同时，资本在社会化生产的循环链路中不断通过对劳动者的剥削和商品价值增殖的过程来构建起利益的势垒。<font color=red><b>在消费社会中，需求侧铺展为更为精细的标签画像，性别、地域乃至年龄、偏好都服务于消费本身，个体的反抗在博取他人认同和辨识的消费中转化为心理层面的满足感，我们消费的并不再是物的单一使用价值，而是通过消费体现社会地位与身份的认同，从而无形地消解了资本主义体制下社会再生产中统治阶级的褫夺原罪，而参与其中的无产阶级在集体无意识中为资本主义生产―利润体系的高效运转和规模扩大贡献了正向力量，因此消费作为符号意义体系结构，是现代资本主义社会合法性的根据。</b></font></p>
<p>另一方面，消费主义又利用了性别等领域的对立。性别化消费将商品赋予性别气质，建立身份标签和消费的主观联系，将消费行为注入了性别化符号的价值，实现了资本更为隐性的增殖。</p>
<h4 id="叙事的艺术" class="headerLink">
    <a href="#%e5%8f%99%e4%ba%8b%e7%9a%84%e8%89%ba%e6%9c%af" class="header-mark"></a>叙事的艺术</h4><p>资本主义与社会生活的深度嵌合不仅表现在经济生活的每一寸角落，还从话语形态上掌握了任何封建社会都无可比拟的控制权。</p>
<p>鉴于资本主义制度本身所解放的生产力和带动的科技进步普遍性地提高了社会群体的文化水平，诉求多元化既成为资产阶级的重大威胁，也恰好为利益团体和边缘群体的割裂提供了社会基础。<font color=red><b>价值的解释权作为资产阶级剥削剩余价值的衍生成果，提供了软暴力叙事的支撑。</b></font>相较于马克思笔下强调人的解放和价值肯定的共产主义理想社会，资本主义则恰恰以异化劳动的方式将人赋以高度社会分工体系下更为机械的存在。人们的工作成为换取商品的任务，劳动被流水线式的生产进一步单维化，在维持生计、满足物欲的静观生活方式中，资本主义秩序在事实上消解了人的价值，人沦为了商品的买家和生产的资源，于是为身份政治等人民内部矛盾创造了意识缺口。</p>
<h3 id="稳定性维系" class="headerLink">
    <a href="#%e7%a8%b3%e5%ae%9a%e6%80%a7%e7%bb%b4%e7%b3%bb" class="header-mark"></a>稳定性维系</h3><h4 id="议程的垄断" class="headerLink">
    <a href="#%e8%ae%ae%e7%a8%8b%e7%9a%84%e5%9e%84%e6%96%ad" class="header-mark"></a>议程的垄断</h4><p>如果说资产阶级实现前述目标的核心权力是传播议程的设定，那么后续一系列标签的塑造则是议程控制的现实表现。压制民众躁动，首先要削弱工人的阶级意识，以“新闻自由”之名实现资本对舆论操纵的自由，从而在实际上剥夺了民众知情的自由；<font color=red><b>以话语权力的收敛将焦点从阶级斗争转移，重塑人们的价值观和矛盾指向的对象，从而将纵向的阶级矛盾迁移为横向的身份矛盾，生产力与生产关系、经济基础与上层建筑的基本矛盾由此蒙上了面纱。</b></font><sup id="fnref2:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></p>
<p>随着金融资本的发展，资本主义统治依托资本符号的形式自由和契约关系实现了更优的形式隐蔽性，金融资本攫取了相当可观的、依赖于历史建构的文化权力，为维系稳定性的手段披上了合法的外衣和真理性的背书。</p>
<h4 id="结构性规训" class="headerLink">
    <a href="#%e7%bb%93%e6%9e%84%e6%80%a7%e8%a7%84%e8%ae%ad" class="header-mark"></a>结构性规训</h4><p><font color=red><b>通过制造地域矛盾、性别矛盾、族裔和宗教差异以及宣传媒体控制等手段，资产阶级得以削弱人民的团结力量，使人们更关心个人利益和短期满足，忽视阶级斗争和资本对劳动的剥削。通过这些结构性的规训手段，资本主义下的生产关系被装裱为无主体的权力关系，于是消解了经济基础的决定作用，把社会斗争形式分解为多元且离散的要素和碎片化的叙事。</b></font><sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>人们的注意力刻画于微观个体的生存状态，英雄史观代替了人民史观，也便有意地孤立了阶级的使命。在资产阶级媒介的宣教下，这些身份标签意义下的个体不再是社会生产关系意义上的个体，也就剥离了马克思关于“人是一切社会关系的总和”<sup id="fnref3:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>的本质。进而，无产阶级在抽象个体的论调中，从原本革命主体力量的地位坠为被排除在社会主体结构之外的边缘存在。</p>
<h4 id="身份政治神话" class="headerLink">
    <a href="#%e8%ba%ab%e4%bb%bd%e6%94%bf%e6%b2%bb%e7%a5%9e%e8%af%9d" class="header-mark"></a>身份政治神话</h4><p><font color=red><b>当代资本主义话语体系下大肆宣扬的地域、性别等横向矛盾构建了一套温和的“种族隔离”机制，通过强化刻板印象和生理性差异，诱导群众相互攻讦、以个体的极化抹煞作为同为被资本主义制度系统性压迫的集体的团结可能性。</b></font></p>
<p>不仅资产阶级在议题上制造割裂，资本主义生产体系本身也在提供分化的社会基础，企业中普遍存在的职业性别歧视和工资差异刻意放大了群体间的差异，而以西方发达资本主义国家代表性的以“宠坏”弱势、边缘群体的身份政治手段，则进一步迫使本就可怜的底层个体不得不趋附于多元文化主义叙事下的资本主义政治制度，成为意识自觉的现有体制维护者。<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup></p>
<p>性别议题原本是平权主义的分支，对女性权益的维护应当是消除传统桎梏尚未完全解体的性别歧视与刻板印象。然而，在资产阶级蛊惑下，性别标签所争论的群体特质，却恰恰潜移默化地成为扩大隔阂的帮凶。值得一提的是，从生物学上说，男女之间的基因演化最终是趋同的，男性与女性不同基因对其认知与行为模式差异的影响远远小于外在环境等因素。但资本主义性别叙事下的女权主义中将反抗精神塑造为一种“弱势者的群体皈依”，巧妙地忽视了话语权的分野并非存在于性别，使女本位和资本主义本身深度耦合，以性别压迫反抗逃避了阶级斗争，强化了压迫本身的土壤。事实上，当代妇女解放与女性意识的觉醒原本就是在后工业化时代，社会生产关系中的性别差异被机器的运用所逐渐抹平、女性大规模参与到现代生产活动之中的成果，如今身处在父权制与消费符号主义双重夹击的女性，在这样的引导下，攻讦男性却成为了她们唯一的出路。</p>
<p><font color=red><b>身份政治表面上看似极具反抗力量，实际成为了与资本主义相当匹配的意识形态框架，即拥有实质地位的资产阶级可以通过舆论、选举、集体叙事的三位一体将阶级意识转变为政治权力交接中的横向议题，而掌握议题主动权的资产阶级则永远处于政治权力的舞台之上。</b></font><sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup></p>
<h3 id="归宿" class="headerLink">
    <a href="#%e5%bd%92%e5%ae%bf" class="header-mark"></a>归宿</h3><p>资本主义身份叙事本质上是基于符号学将无产阶级分化瓦解的统治手段，根本目的是削弱其反抗的意识、掩盖阶级矛盾，以实现稳固统治。被割裂的人民群众不仅成为自相厮杀的棋子，也在内部对立中进一步在思想和物质基础上固化了资本主义制度。</p>
<p>而建立在人民内部矛盾上的、文化斗争形式的身份政治运动无法触及资本主义私有制和剥削的本质，无法真正改变政治经济不平等的现实。然而，资本主义分化民众所催生的身份焦虑，恰恰引发了被统治群体的普遍极化。<font color=red><b>民众的撕裂虽然短期缓和了阶级上的矛盾，却进一步瓦解了资本主义政治体制存在的基础，反过来损害资本主义生产力的发展，最终必然迎来阶级意识的觉醒和资本主义被新生产关系取代的必然结局。</b></font></p>
<p style="text-align:right">（3419字）</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>《去依附》温铁军&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>（法）让·鲍德里亚著；夏莹译. 符号政治经济学批判[M]. 南京：南京大学出版社, 2015.01.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>中共中央马克思恩格斯列宁斯大林著作编译局编译. 马克思恩格斯全集[M]. 北京：人民出版社, 2014.08.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>（法）米歇尔·福柯（Michel Foucault）著；刘北成，杨远婴译. 规训与惩罚 监狱的诞生[M]. 北京：生活·读书·新知三联书店, 2003.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>南希.弗雷泽. 超越身份政治和政治正确：资本主义作为制度化的社会秩序.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>宋朝龙.后现代主义身份政治的衰颓与新民粹主义的崛起[J].北京行政学院学报,2020(02):114-121.DOI:10.16365/j.cnki.11-4054/d.2020.02.014.&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>]]></description>
</item><item>
    <title>政治经济学导论</title>
    <link>https://blog.ralvines.top/zzjjxdl/</link>
    <pubDate>Thu, 29 Jun 2023 20:20:40 &#43;0800</pubDate><author>
                        <name>Ralvine</name><uri>https://blog.ralvines.top/about.md</uri><email>ralvine@163.com</email></author><guid>https://blog.ralvines.top/zzjjxdl/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="https://z1.ax1x.com/2023/10/23/piAGKJ0.png" referrerpolicy="no-referrer">
            </div><div class="details admonition quote open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-quote-right fa-fw"></i>课程信息<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">🎓 经济学院<br>
🕙 2022-2023 夏<br>
🧑‍🏫 俞彬<br>
📝 40%平时（两次问卷调查），60%论文</div>
        </div>
    </div>
<h2 id="参考" class="headerLink">
    <a href="#%e5%8f%82%e8%80%83" class="header-mark"></a>参考</h2><ul>
<li>PPT（导论）
<ul>
<li>Lecture1</li>
<li>Lecture2</li>
<li>Lecture3</li>
<li>Lecture4</li>
<li>Lecture5</li>
<li>Lecture6</li>
</ul>
</li>
<li><a href="https://classroom.zju.edu.cn/coursedetail?course_id=47818&amp;tenant_code=112" target="_blank" rel="noopener noreferrer">智云课堂回放</a></li>
</ul>
<h2 id="lecture1" class="headerLink">
    <a href="#lecture1" class="header-mark"></a>Lecture1.</h2><blockquote>
<p>夏一周</p>
</blockquote>
<ul>
<li>客观/主观价值论（信用、劳动）</li>
<li>货币
<ul>
<li>明朝货币（农业、税收）</li>
<li>俄乌战争、汇率（资源）</li>
<li>美元（资产、国债，农产品、石油、高新制造）</li>
<li>长征、抗币（与盐、农产品的锚定）</li>
<li>国民党法币（铸币税）</li>
<li>人民币国际化（工业门类）</li>
</ul>
</li>
</ul>
<h2 id="lecture2" class="headerLink">
    <a href="#lecture2" class="header-mark"></a>Lecture2.</h2><blockquote>
<p>夏三周（引用政治经济学春二周的内容，基本一致）</p>
</blockquote>
<ul>
<li>货币
<ul>
<li>螃蟹战略、石油美元，结算系统 SWIFT -&gt; 中国</li>
<li>数字人民币（DCEP） 1.0 -&gt; 2.0（移动支付）-&gt; 3.0，DC、EP</li>
<li>大明宝钞、民国法币/金圆券、美元/港币（联系汇率制）、人民币，锚定资产 &lt;-&gt; 负债</li>
<li>货币：农业（耕地红线）、制造业（完整工业体系）、资产（清洁能源）、文明</li>
<li>核心：劳动价值论、历史唯物主义</li>
</ul>
</li>
<li>阶级和生产关系的变革
<ul>
<li>商鞅变法：废井田（王有） -&gt; 私有、买卖</li>
<li>江南豪强 -&gt; 科举 -&gt; 资本文官（户部官员不让浙江人担任、万里国本之争）</li>
<li>明朝
<ul>
<li>土地兼并：对农民生产资料的剥夺</li>
<li>三大阶级、民众鼓噪
<ul>
<li>封建官僚、资本官僚、民众</li>
<li>《显微镜的大明》</li>
</ul>
</li>
<li>失败：资产阶级的软弱性</li>
</ul>
</li>
<li>国富论关于三大阶级论述
<ul>
<li>地主、工资生活的阶级、靠利润生活的阶级</li>
</ul>
</li>
<li>资本主义生产关系出现的两个条件
<ul>
<li>失去生产资料、人身自由</li>
<li>少数人的货币积累</li>
</ul>
</li>
</ul>
</li>
<li>价值和资本
<ul>
<li>特殊商品：劳动力，必要劳动时间和剩余劳动时间</li>
<li>价值与剩余价值（两种形式：绝对/相对）</li>
<li>不变资本与可变资本，资本（完成价值增殖的钱）</li>
<li>资本主义制度的工资本质（计时/计件，后者剥削更隐蔽）</li>
<li>高强度长时间工作和高工资的因果关系</li>
</ul>
</li>
</ul>
<h2 id="lecture3" class="headerLink">
    <a href="#lecture3" class="header-mark"></a>Lecture3.</h2><blockquote>
<p>夏四周</p>
</blockquote>
<ul>
<li>中国资本主义黄金时代
<ul>
<li>买办</li>
<li>资产阶级的矛盾诉求</li>
<li>自由资本主义到垄断资本主义</li>
</ul>
</li>
<li>剩余价值学说
<ul>
<li>商品化的劳动力：价值和使用价值</li>
<li>资本主义生产过程：劳动+价值增殖</li>
<li>流通领域的劳动力和商品买卖和非流通领域的价值增殖（剥削）</li>
<li>企业亏本：私人劳动转换为社会劳动</li>
<li>私有化和苏联解体</li>
<li>两种形式：绝对、相对</li>
<li>工资本质和形式：计时、计件</li>
</ul>
</li>
<li>一些实例
<ul>
<li>湖畔大学和滴滴打车</li>
<li>流量的政治经济学解释
<ul>
<li>消费主义</li>
<li>标签化和群体割裂</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="lecture4" class="headerLink">
    <a href="#lecture4" class="header-mark"></a>Lecture4.</h2><blockquote>
<p>夏五周</p>
</blockquote>
<ul>
<li>历史虚无主义、解构</li>
<li>剩余价值、利润转化
<ul>
<li>不变资本、可变资本</li>
<li>平均利润率</li>
<li>价值、价格转化</li>
</ul>
</li>
<li>产业资本、商业资本</li>
<li>借贷资本、银行资本
<ul>
<li>三家私有银行</li>
</ul>
</li>
<li>股份制、“资本民主化”
<ul>
<li>股民不是资产阶级</li>
<li>白领、自由职业、微企业</li>
<li>大企业对中小企业的剥削</li>
</ul>
</li>
<li>生产关系与上层建筑
<ul>
<li>日本财阀</li>
<li>特朗普、资本全球主义和经济民族主义</li>
</ul>
</li>
</ul>
<h2 id="lecture5" class="headerLink">
    <a href="#lecture5" class="header-mark"></a>Lecture5.</h2><blockquote>
<p>夏六周</p>
</blockquote>
<ul>
<li>资本主义再生产
<ul>
<li>资本积累</li>
<li>二十年代美国</li>
</ul>
</li>
<li>两极分化、二八定律</li>
<li>平台、监视资本主义
<ul>
<li>数据监管</li>
</ul>
</li>
</ul>
<h2 id="lecture6" class="headerLink">
    <a href="#lecture6" class="header-mark"></a>Lecture6.</h2><blockquote>
<p>夏七周</p>
</blockquote>
<ul>
<li>人工智能时代的私有制剥削</li>
<li>费米悖论、人类的未来</li>
<li>周期性金融危机</li>
<li>发达资本主义国家的全国掠夺和剥削</li>
</ul>
<h2 id="lecture7" class="headerLink">
    <a href="#lecture7" class="header-mark"></a>Lecture7.</h2><blockquote>
<p>夏八周</p>
</blockquote>
<h2 id="期末论文" class="headerLink">
    <a href="#%e6%9c%9f%e6%9c%ab%e8%ae%ba%e6%96%87" class="header-mark"></a>期末论文</h2><p><em>（约定 「资本主义是万恶的」）</em>‘</p>
<h2 id="资本无序扩张的三十年" class="headerLink">
    <a href="#%e8%b5%84%e6%9c%ac%e6%97%a0%e5%ba%8f%e6%89%a9%e5%bc%a0%e7%9a%84%e4%b8%89%e5%8d%81%e5%b9%b4" class="header-mark"></a>资本无序扩张的三十年</h2><p>这是资本无序扩张的第三十年，与泡沫般飞涨的资本主义繁荣神话相伴的是，工业化和市场化浪潮下生产资料的结构性错配在其让渡于资本权力的进程中精妙地编织起一套无处挣脱的生产方式和叙事体系，即便是矗立于社会金字塔尖的名义精英也潜意识地驯服于资本-消费符号构成的全景社会之内、安适于新贵族般的森严而坚实的壁龛之中。</p>
<p>资本主义首要刻画的是附着于人性原始欲望的商品世界童话。在纸醉金迷的浪潮中，头脑聪明、精于算计的“精致利己主义”轻而易举地渗透了道德意识形态的高地，以财富导向的社会天梯的攀附者们，自发地戴上了旧时代残存的冠冕，在阶级的金字塔沿互相倾轧。在这个效率第一的时代，几乎没有人意识到自己身处于资本疯狂自我增殖的子宫之中，由其浇筑的雇佣制社会化再生产链路和附着于其间的劳动者和资本家，无非是燃料和傀儡的区别，所有人生来的目的便是幻想在资本浇筑的符号幻觉里叱咤风云，他们无一例外地在攫取财富和消费需求的周期里麻木地寻求物欲的安慰，劳作成了自我意识存续的手段本身。</p>
<p>而在商品和消费为通用语言的符号社会里，无产阶级以打工人的身份被赋予了更广泛、更系统性的剥削定位，工人不仅仅作为生产环节的劳动资料被以工资的形式贴上价格标签自由出卖，同时也在货币符号的诱惑下成为劳动产物的需求端被更为精细地剖分为消费主义的二次收割对象。被褫夺了时间和生活的工薪阶层在博取他人认同和辨识的消费行为中无形地将反抗意识转换为心理层面异化了的满足感，财富和消费定义了新的身份价值标签，于是人们并不再孤立地居于物的使用价值作用范畴之中，而是以消费重新勾勒了社会地位与身份认同，在这里，剥削的原罪被巧妙地消弭，无产阶级在集体无意识中反而为资本主义生产―利润体系的高效运转和规模扩大贡献了正向反馈，成为其合法性的建筑师和辩经者。</p>
<p>随着资本扩张悄然僭越了将它释放出来的设计师们所划定的效率范畴，文化意识形态和政治结构便在这套全球化的资本主义生产体系下显得势单力薄，在私有财产神圣不可侵犯的神话里，富人与穷人间事实上如猿猴与人类般地经历了二次自然选择，塑造了从生活方式到价值观的社会隔离，于是从小镇成长起来的新兴精英阶层渐渐失去了和底层共情的意愿，剥削不再是可耻的，福报和奋斗的措辞从老大哥修正主义批判的辞典里焕发新生，一面是劳动消费负债三重枷锁嵌入焦虑和麻木的普遍神色，群众推动历史的史观则被英雄和个体的抽象叙事缓缓取代，另一面是资本的提线木偶将贪婪的目光投射于涵盖了政治权力和舆论场的一切尚未触及的领域，不遗余力地把社会斗争形式分解为多元且离散的要素，被身份标签细化瓦解的无产者则只能不平等地收获可怜的施舍。一批高级打工人陷入归化小资产阶级的自我实现预言之中，另一批人则陷入理论荒芜的桎梏，或是在新自由主义的幻想中极化，或是在宏大叙事中将泛左翼与民族主义联姻。</p>
<p>然而固有的阶级分化和生产力的解放也在反噬着资本储备的统治艺术，于是，资本主义的大厦之巅积聚起几朵不起眼的乌云——阶级分化愈发明显，贫富差距深渊般无法逾越；原本做大蛋糕和技术进步所革新的社会面貌愈发迟滞，衰退下行的危机不再遥远，透支未来则成了唯一的出路。均质化的资本伴随着社会逐渐失去迭代的活力，并向上层建筑深度渗透，即便是婚姻和家庭也悄然开始冠以资本价值的度量，新的媒介也从技术本位的工具趋向沦为资本的喉舌，而后者正试图复刻互联网从开源精神指导的通信载体到充斥着被资本打包成商品而肆意操纵的用户囚笼的规训路径，从而使高度信息化的社会在模糊虚拟与现实的过程中，赋予大多数底层人从未意识到第四层枷锁，即赛博朋克式地将计算机幻化为穷人的假上帝。一边是智能机械弱化了劳动者的议价能力，另一边过剩的人力则被进一步地压缩至娱乐至死的虚拟幻境之中。从住房到医疗，资本的逐利性前所未有的暴露出来，甚至连教育这一社会阶层流动的血管也被这些癌细胞肆意地蚕食。</p>
<p>由是，觉醒意识开始从体力无产者蔓延至脑力无产者，许多被忽视已久的概念和思想得以重新审视。当资本高速发展可以些许惠及他们的时候，他们抛弃了这些概念；当资本无法容纳生产力进步所带来的群体诉求时，这些概念又在他们脑海中回归了。于是，无产阶级重新开始用“资本家”称呼企业家，用“剥削”描述雇佣；资本集团则深感不安，渴望再一次用其垄断的话术要求人们相信今天所遭受的生活困苦应当归咎于奋斗和劳动不够。但受到剥削的群体意识俨然在客观现实中导向了资本的掠夺本质，也唤起了拒绝为无序扩张的资本服务、为一小撮垄断资产阶级的“特权”卖命的抗争思潮，而后者正是在资本主义的叙事掩饰下，通过利润和税金等形式无偿地占有工人创造的大量财富，贪婪地榨取劳动人民的血汗。</p>
<p>这是资本无序扩张的第三十年，也是云谲波诡、山雨欲来的一年。资本的无序扩张正将历史唯物主义同广大的无产阶级重新耦合，敏锐的人们正向更先进的生产力和生产关系睁眼望去。</p>]]></description>
</item><item>
    <title>数据建模与分析</title>
    <link>https://blog.ralvines.top/sjjm/</link>
    <pubDate>Wed, 28 Jun 2023 20:20:40 &#43;0800</pubDate><author>
                        <name>Ralvine</name><uri>https://blog.ralvines.top/about.md</uri><email>ralvine@163.com</email></author><guid>https://blog.ralvines.top/sjjm/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="https://z1.ax1x.com/2023/10/23/piAW5eH.png" referrerpolicy="no-referrer">
            </div><div class="details admonition quote open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-quote-right fa-fw"></i>课程信息<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">🎓 数学科学学院<br>
🕙 2022-2023 春夏<br>
🧑‍🏫 郭正初<br>
📝 20%课后作业，15%读书报告，15%编程作业，50%期末考试</div>
        </div>
    </div>
<h2 id="参考" class="headerLink">
    <a href="#%e5%8f%82%e8%80%83" class="header-mark"></a>参考</h2><ul>
<li>PPT
<ul>
<li>Ch1. 机器学习概论</li>
<li>Ch2. 感知机</li>
<li>Ch3. k近邻</li>
<li>Ch4. 朴素贝叶斯</li>
<li>Ch5. 决策树</li>
<li>Ch6. 逻辑斯蒂回归、最大熵模型</li>
<li>Ch7. 支持向量机</li>
<li>Ch8. AdaBoost</li>
<li>Ch13. 无监督学习概论</li>
<li>Ch14. 聚类方法</li>
<li>谱聚类</li>
<li>Ch15. 奇异值分解</li>
<li>Ch16. 主成分分析</li>
<li>Ch19. 马尔可夫链蒙特卡罗法</li>
</ul>
</li>
<li>《统计学习方法（第二版）》，李航</li>
<li><a href="https://classroom.zju.edu.cn/coursedetail?course_id=51611&amp;tenant_code=112" target="_blank" rel="noopener noreferrer"><em>智云课堂回放</em></a></li>
</ul>
<h2 id="ch1-机器学习概论" class="headerLink">
    <a href="#ch1-%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e6%a6%82%e8%ae%ba" class="header-mark"></a>Ch1. 机器学习概论</h2><blockquote>
<p>春一周</p>
</blockquote>
<ul>
<li>人工智能
<ul>
<li>研究目的、内容、表现形式</li>
<li>发展历程、现状</li>
<li>顶刊、顶会</li>
</ul>
</li>
<li>机器学习（统计学习理论）
<ul>
<li>定义（经验）</li>
<li>顶刊、顶会</li>
<li>应用：NLP、CV&hellip;</li>
<li>区别联系
<ul>
<li>数据挖掘（噪声、仓储）</li>
<li>模式识别</li>
</ul>
</li>
</ul>
</li>
<li>大数据
<ul>
<li>4&quot;V&quot;: 量大、类多、实时、密度低</li>
</ul>
</li>
<li>深度学习（ML分支）
<ul>
<li>深度神经网络，假设空间</li>
<li>特征学习</li>
</ul>
</li>
<li>统计机器学习（数据预测与分析）
<ul>
<li>数据驱动</li>
<li><strong>分类</strong>
<ul>
<li>监督/半监督/无监督/强化学习
<ul>
<li>数据标注，概率分布</li>
<li>连续互动</li>
</ul>
</li>
<li>概率/非，线性/非，参数/非</li>
<li>条件概率分布/函数
<ul>
<li>参数维度</li>
</ul>
</li>
<li>在线/批量/离线</li>
<li>贝叶斯/核方法</li>
</ul>
</li>
<li>三要素
<ul>
<li>模型（决策函数/条件概率/参数空间）</li>
<li>策略（损失/风险函数，经验/结构风险最小化）</li>
<li>算法（最优化问题）</li>
</ul>
</li>
<li>模型评估和选择
<ul>
<li>训练误差、测试误差</li>
<li>过拟合、欠拟合</li>
<li>正则化、交叉验证</li>
<li>泛化能力/误差（对未知数据）</li>
<li>集中不等式</li>
</ul>
</li>
<li>生成与判别模型
<ul>
<li>判别方法（直接学习决策函数/概率分布）</li>
<li>生成方法（从联合概率分布到条件概率分布）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="ch2-感知机" class="headerLink">
    <a href="#ch2-%e6%84%9f%e7%9f%a5%e6%9c%ba" class="header-mark"></a>Ch2. 感知机</h2><blockquote>
<p>春二周</p>
</blockquote>
<ul>
<li>线性可分性</li>
<li>点到超平面距离、损失函数</li>
<li>随机梯度下降
<ul>
<li>学习率</li>
<li>不唯一（初值、误分类点顺序）</li>
<li><strong>收敛性证明</strong></li>
</ul>
</li>
<li>对偶形式（优点）
<ul>
<li><strong>Gram 矩阵</strong></li>
</ul>
</li>
</ul>
<h2 id="ch3-k近邻" class="headerLink">
    <a href="#ch3-k%e8%bf%91%e9%82%bb" class="header-mark"></a>Ch3. k近邻</h2><blockquote>
<p>春三周</p>
</blockquote>
<ul>
<li>三要素：k，度量，决策规则</li>
<li>优点、缺点（复杂度）</li>
<li>选 k （误差最小、k小复杂过拟合）</li>
<li>kd树（k维）
<ul>
<li>构造</li>
<li>对kNN检索</li>
</ul>
</li>
</ul>
<h2 id="ch4-朴素贝叶斯" class="headerLink">
    <a href="#ch4-%e6%9c%b4%e7%b4%a0%e8%b4%9d%e5%8f%b6%e6%96%af" class="header-mark"></a>Ch4. 朴素贝叶斯</h2><blockquote>
<p>春四周</p>
</blockquote>
<ul>
<li>样本空间、全概率公式</li>
<li>期望风险最小化、后验概率最大化</li>
<li>极大似然法
<ul>
<li>对数似然</li>
<li>估计值/量</li>
<li>朴素贝叶斯法的参数估计</li>
</ul>
</li>
<li>贝叶斯估计（极大似然估计、拉普拉斯平滑）</li>
<li></li>
</ul>
<h2 id="ch5-决策树" class="headerLink">
    <a href="#ch5-%e5%86%b3%e7%ad%96%e6%a0%91" class="header-mark"></a>Ch5. 决策树</h2><blockquote>
<p>春五周</p>
</blockquote>
<ul>
<li>分类和回归</li>
<li>CLS</li>
<li>ID3
<ul>
<li>熵、信息量</li>
<li>条件熵、经验熵/条件熵</li>
<li>信息增益、互信息</li>
<li>计算信息增益、选择最优特征</li>
</ul>
</li>
<li>C4.5（信息增益比）
<ul>
<li>连续属性：二元分割</li>
</ul>
</li>
<li>剪枝
<ul>
<li>损失函数</li>
</ul>
</li>
<li>CART
<ul>
<li>基尼指数</li>
<li>回归树、分类树</li>
<li><strong>剪枝</strong></li>
</ul>
</li>
</ul>
<h2 id="ch6-逻辑斯蒂回归最大熵模型" class="headerLink">
    <a href="#ch6-%e9%80%bb%e8%be%91%e6%96%af%e8%92%82%e5%9b%9e%e5%bd%92%e6%9c%80%e5%a4%a7%e7%86%b5%e6%a8%a1%e5%9e%8b" class="header-mark"></a>Ch6. 逻辑斯蒂回归、最大熵模型</h2><blockquote>
<p>春六周</p>
</blockquote>
<ul>
<li>Logistic分布
<ul>
<li>分布函数、密度函数</li>
<li>Sigmoid、tanh</li>
</ul>
</li>
<li>Logistic回归
<ul>
<li>二项</li>
<li>似然函数</li>
<li>多项</li>
</ul>
</li>
<li>最大熵模型
<ul>
<li>学习</li>
<li>极大似然估计</li>
</ul>
</li>
<li>最优化
<ul>
<li>梯度下降</li>
<li>牛顿、拟牛顿
<ul>
<li>黑塞矩阵</li>
<li>正定矩阵（近似）</li>
</ul>
</li>
<li>DFP</li>
<li>BFGS</li>
<li>Broyden</li>
<li>改进迭代尺度</li>
<li>梯度上升、随机梯度上升</li>
</ul>
</li>
</ul>
<h2 id="ch7-支持向量机" class="headerLink">
    <a href="#ch7-%e6%94%af%e6%8c%81%e5%90%91%e9%87%8f%e6%9c%ba" class="header-mark"></a>Ch7. 支持向量机</h2><blockquote>
<p>春七周</p>
</blockquote>
<ul>
<li>线性可分、硬间隔最大化</li>
<li>线性不可分、软间隔最大化</li>
<li>非线性、核函数</li>
<li>序列最小化优化算法</li>
<li>误差分析</li>
</ul>
<h2 id="ch8-adaboost" class="headerLink">
    <a href="#ch8-adaboost" class="header-mark"></a>Ch8. AdaBoost</h2><blockquote>
<p>春八周</p>
</blockquote>
<ul>
<li>强可学习、弱可学习</li>
<li>Boosting、AdaBoost
<ul>
<li>权重、系数</li>
<li>误差分析</li>
<li>前向分步算法</li>
<li>提升树算法
<ul>
<li>回归问题</li>
</ul>
</li>
<li>梯度提升算法</li>
</ul>
</li>
</ul>
<h2 id="ch13-无监督学习概论" class="headerLink">
    <a href="#ch13-%e6%97%a0%e7%9b%91%e7%9d%a3%e5%ad%a6%e4%b9%a0%e6%a6%82%e8%ae%ba" class="header-mark"></a>Ch13. 无监督学习概论</h2><blockquote>
<p>夏一周</p>
</blockquote>
<ul>
<li>损失最小压缩
<ul>
<li>聚类：硬、软</li>
<li>降维</li>
</ul>
</li>
<li>概率模型
<ul>
<li>混合、概率图（有向、无向）</li>
<li><strong>估计</strong></li>
</ul>
</li>
<li>三要素：模型、策略、方法</li>
<li>话题分析（LDA）</li>
<li>图分析
<ul>
<li>PageRank 计算</li>
</ul>
</li>
</ul>
<h2 id="ch14-聚类方法谱聚类" class="headerLink">
    <a href="#ch14-%e8%81%9a%e7%b1%bb%e6%96%b9%e6%b3%95%e8%b0%b1%e8%81%9a%e7%b1%bb" class="header-mark"></a>Ch14. 聚类方法、谱聚类</h2><blockquote>
<p>夏二周，夏三周</p>
</blockquote>
<ul>
<li>距离
<ul>
<li>Minkowski、欧式、曼哈顿、Chebyshev</li>
<li>马氏、协方差矩阵、相关系数、夹角余弦</li>
</ul>
</li>
<li>簇
<ul>
<li>各种定义</li>
<li>特征划分：散布矩阵、协方差矩阵</li>
<li>类间距离（连接）：最短（单）、最长（完全）、中心、平均</li>
</ul>
</li>
<li>层次聚类
<ul>
<li>聚合、分裂</li>
<li>合并规则、停止条件</li>
</ul>
</li>
<li>k均值
<ul>
<li>欧氏距离、损失函数</li>
<li>初始中心选取</li>
<li>k的选取（平均直径不再增加）</li>
</ul>
</li>
</ul>
<h2 id="ch15-奇异值分解" class="headerLink">
    <a href="#ch15-%e5%a5%87%e5%bc%82%e5%80%bc%e5%88%86%e8%a7%a3" class="header-mark"></a>Ch15. 奇异值分解</h2><blockquote>
<p>夏四周</p>
</blockquote>
<ul>
<li>特征分解/谱分解
<ul>
<li>特征向量、特征值、特征多项式</li>
<li>方阵可对角化&amp;特征向量线性无关</li>
<li>分解: Q, $\Lambda$</li>
<li>实对称情形: 逆</li>
</ul>
</li>
<li>定义
<ul>
<li>分解: U, V, $\Sigma$</li>
<li>奇异值、左右奇异向量</li>
<li>不唯一</li>
<li>存在性、<strong>证明</strong>（从V到U的构造）</li>
</ul>
</li>
<li>类型
<ul>
<li>完全分解</li>
<li>紧凑分解（r，等秩）</li>
<li>截断分解（k，实际）</li>
</ul>
</li>
<li>性质
<ul>
<li>线性变换解释（分解：旋转、缩放、旋转）</li>
<li>等价特征分解（V、U代表的特征向量）</li>
<li>奇异向量构成的标准正交基（由正交性）</li>
</ul>
</li>
<li>计算</li>
<li>矩阵近似
<ul>
<li>F范数</li>
<li>矩阵的F范数与其奇异值的关系</li>
<li>平方损失下的最优近似、<strong>证明</strong></li>
<li>外积展开式、最优近似矩阵的计算</li>
</ul>
</li>
</ul>
<h2 id="ch16-主成分分析" class="headerLink">
    <a href="#ch16-%e4%b8%bb%e6%88%90%e5%88%86%e5%88%86%e6%9e%90" class="header-mark"></a>Ch16. 主成分分析</h2><blockquote>
<p>夏五周</p>
</blockquote>
<ul>
<li>数据分析、机器学习预处理</li>
<li>思路
<ul>
<li>规范化：平均值0，方差1</li>
<li>正交变换、线性相关转无关变量（主成分）</li>
<li>方差和最大化的正交变换（椭圆长轴）</li>
</ul>
</li>
<li>定义
<ul>
<li>均值向量$\mu$、协方差矩阵、</li>
</ul>
</li>
<li>总体PCA</li>
<li>样本PCA</li>
</ul>
<h2 id="ch19-马尔可夫链蒙特卡罗法" class="headerLink">
    <a href="#ch19-%e9%a9%ac%e5%b0%94%e5%8f%af%e5%a4%ab%e9%93%be%e8%92%99%e7%89%b9%e5%8d%a1%e7%bd%97%e6%b3%95" class="header-mark"></a>Ch19. 马尔可夫链蒙特卡罗法</h2><ul>
<li>蒙特卡洛法
<ul>
<li>直接抽样</li>
<li>接受-拒绝抽样（建议分布）</li>
<li>期望/积分计算</li>
</ul>
</li>
<li>马尔可夫链
<ul>
<li>时间齐次</li>
<li>高阶</li>
<li>转移概率矩阵、随机矩阵</li>
<li>平稳分布（充要条件）</li>
<li>连续状态、转移核</li>
<li>性质
<ul>
<li>不可约</li>
<li>非周期</li>
<li>正常返</li>
<li>唯一平稳分布（有限、无限）</li>
<li>遍历定理</li>
<li>可逆</li>
</ul>
</li>
</ul>
</li>
<li>马尔可夫链蒙特卡罗法
<ul>
<li>燃烧期</li>
<li>步骤</li>
</ul>
</li>
<li>Metropolis-Hastings
<ul>
<li>单分量</li>
</ul>
</li>
<li>吉布斯抽样
<ul>
<li>抽样计算</li>
</ul>
</li>
</ul>
<h2 id="历年卷" class="headerLink">
    <a href="#%e5%8e%86%e5%b9%b4%e5%8d%b7" class="header-mark"></a>历年卷</h2><h3 id="20-21-春夏" class="headerLink">
    <a href="#20-21-%e6%98%a5%e5%a4%8f" class="header-mark"></a>20-21 春夏</h3><ul>
<li>Kd树 书上例题 找最近邻</li>
<li>熵H(p)的定义，证明H(p)在0到log(n)之间</li>
<li>朴素贝叶斯 书上例题</li>
<li>SVM含义以及与感知机的区别
<ul>
<li>推导出 SVM 的对偶问题</li>
<li>如何通过对偶问题的解得到原问题的解</li>
</ul>
</li>
<li>聚类 书上例题</li>
<li>看图求马尔科夫链的转移概率矩阵和平稳分布</li>
<li>奇异值分解存在性唯一性讨论，并给出分解过程</li>
<li>给了一个矩阵，对其进行主成分分析</li>
<li>决策树中的信息增益g(D,A)的用处
<ul>
<li>剪枝的意义</li>
</ul>
</li>
<li>课程建议</li>
</ul>
<h3 id="21-22-春夏" class="headerLink">
    <a href="#21-22-%e6%98%a5%e5%a4%8f" class="header-mark"></a>21-22 春夏</h3><ul>
<li>简述决策树的一种特征选择准则的定义，说明准则对决策树的影响（大概是这个意思，考信息增益和基尼指数的定义）</li>
<li>kd树构造
<ul>
<li>k近邻模型三要素是什么，k值选择需要注意什么（过拟合和误差）</li>
<li>给定样本数据集，构造kd树</li>
<li>按照构造的kd树求出实例点 （2，4.5）的最近邻</li>
</ul>
</li>
<li>支持向量机：给定线性不可分支持向量机的学习问题
<ul>
<li>软间隔SVM含义</li>
<li>写出对偶形式</li>
<li>求支持向量（好像是，当时只复习了硬间隔，软间隔就摆了）</li>
</ul>
</li>
<li>聚类问题：给定5个样本集合X，选定两个中心点，用k均值聚类算法 将X分成两类 （参考教材例题14.2）</li>
<li>马尔可夫链 和 蒙特卡洛法
<ul>
<li>大致说明 E[f(x)] (概率分布函数为p(x) ) 的计算方法 （大数定理近似样本均值）</li>
<li>给出一条马尔科夫链，求平稳分布（考的书上例题19.7）</li>
</ul>
</li>
<li>主成分分析
<ul>
<li>给定一个m维度的随机变量，求出k个主成分（1&lt;= k &lt;=m)，并且证明</li>
</ul>
</li>
<li>简述感知机，Adaboost，朴素贝叶斯法，logistic模型的学习策略和算法</li>
<li>奇异值分解：矩阵数据忘了 给定一个2*3矩阵A，求A的奇异值分解和紧奇异值分解，并且说明奇异值分解的几何意义</li>
</ul>
<h2 id="论文精读" class="headerLink">
    <a href="#%e8%ae%ba%e6%96%87%e7%b2%be%e8%af%bb" class="header-mark"></a>论文精读</h2><blockquote>
<p>Distance metric learning for large margin nearest neighbor classification.pdf</p>
</blockquote>
<ul>
<li>大边距近邻分类的距离度量学习</li>
</ul>
<h2 id="前辈经验" class="headerLink">
    <a href="#%e5%89%8d%e8%be%88%e7%bb%8f%e9%aa%8c" class="header-mark"></a>前辈经验</h2><blockquote>
<p>期末考比较中规中矩，无小测。</p>
<p>上课就是讲《统计学习方法》中的几章，作业做书的课后题，没有代码作业。 不过去年很多人提建议说要增加代码训练和作业量，今年可能会有所改变</p>
</blockquote>
<p>习题与代码参考：</p>
<ul>
<li>统计学习方法（第二版）习题解答 <a href="https://github.com/datawhalechina/statistical-learning-method-solutions-manual" target="_blank" rel="noopener noreferrer">https://github.com/datawhalechina/statistical-learning-method-solutions-manual</a></li>
<li><a href="https://blog.csdn.net/qq_42911960/article/details/115255714" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/qq_42911960/article/details/115255714</a></li>
<li><a href="https://blog.csdn.net/qq_41562704/article/details/106540274" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/qq_41562704/article/details/106540274</a></li>
<li><a href="https://blog.csdn.net/wang_xinyu/article/details/111497444" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/wang_xinyu/article/details/111497444</a></li>
<li><a href="https://blog.csdn.net/breeze_blows/article/details/85469944" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/breeze_blows/article/details/85469944</a></li>
</ul>
<p>回忆卷：</p>
<ul>
<li><a href="https://www.cc98.org/topic/5356728" target="_blank" rel="noopener noreferrer">https://www.cc98.org/topic/5356728</a></li>
<li><a href="https://www.cc98.org/topic/5116266" target="_blank" rel="noopener noreferrer">https://www.cc98.org/topic/5116266</a></li>
</ul>
<h2 id="参考书目" class="headerLink">
    <a href="#%e5%8f%82%e8%80%83%e4%b9%a6%e7%9b%ae" class="header-mark"></a>参考书目</h2><ul>
<li>《机器学习》，周志华，清华大学出版社，2016.</li>
<li>《The Elements of Statistical Learning》2nd edition, Trevor Hastie, Robert Tibshirani, and Jerome Friedman, Springer 2008.</li>
<li>《Pattern Recognition and Machine Learning》, Chris Bishop,  Springer 2006.</li>
<li>《Learning Theory：An Approximation Theory Viewpoint》, Felipe
Cucker and Ding-Xuan Zhou, Cambridge Univesity Press, 2007.</li>
</ul>]]></description>
</item><item>
    <title>泛函分析</title>
    <link>https://blog.ralvines.top/fhfx/</link>
    <pubDate>Wed, 01 Mar 2023 20:20:40 &#43;0800</pubDate><author>
                        <name>Ralvine</name><uri>https://blog.ralvines.top/about.md</uri><email>ralvine@163.com</email></author><guid>https://blog.ralvines.top/fhfx/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="https://z1.ax1x.com/2023/10/23/piAW5eH.png" referrerpolicy="no-referrer">
            </div><div class="details admonition quote open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-quote-right fa-fw"></i>课程信息<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">🎓 数学科学学院<br>
🕙 2022-2023 春夏<br>
🧑‍🏫 王伟<br>
📝 20%小测，20%作业，60%期末</div>
        </div>
    </div>
<h2 id="参考" class="headerLink">
    <a href="#%e5%8f%82%e8%80%83" class="header-mark"></a>参考</h2><ul>
<li>《实变函数与泛函分析概要（第五版）》王声望，郑维行</li>
<li>课程讲义
<ul>
<li>Ch1.1</li>
<li>Ch1.2</li>
<li>Ch2.1</li>
<li>Ch2.2</li>
<li>Ch3.1</li>
<li>Ch3.2</li>
</ul>
</li>
<li>泛函分析笔记 @Reichtum</li>
<li>课后习题讲解 @Reichtum
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/486354129" target="_blank" rel="noopener noreferrer">度量空间</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/524355026" target="_blank" rel="noopener noreferrer">Banach&amp;Hilbert</a></li>
</ul>
</li>
<li><a href="https://classroom.zju.edu.cn/coursedetail?course_id=48021&amp;tenant_code=112" target="_blank" rel="noopener noreferrer"><em>智云课堂回放</em></a></li>
</ul>
<h2 id="ch1-距离空间" class="headerLink">
    <a href="#ch1-%e8%b7%9d%e7%a6%bb%e7%a9%ba%e9%97%b4" class="header-mark"></a>Ch1. 距离空间</h2><ul>
<li>
<p>定义</p>
<ul>
<li>距离公理：非负、对称、三角不等式</li>
<li>非空即可定义、不唯一</li>
<li>离散距离空间</li>
<li>$\mathbb{R}^n$
<ul>
<li>欧氏距离、复数域</li>
<li><strong>柯西不等式</strong></li>
<li>max定义</li>
</ul>
</li>
<li>连续函数空间$C[a,b]$</li>
<li>$l^p$
<ul>
<li>元素：无限数列、级数绝对收敛</li>
<li>距离定义
<ul>
<li>Holder不等式</li>
<li><strong>Minkowski不等式</strong>、证明</li>
</ul>
</li>
</ul>
</li>
<li>$l^\infty$</li>
<li>$L^p(F)$
<ul>
<li>可测集F</li>
<li>距离定义
<ul>
<li>Holder不等式</li>
<li>Minkowski不等式</li>
</ul>
</li>
</ul>
</li>
<li>$L^\infty$
<ul>
<li>本性有界</li>
<li>本性有界可测、几乎处处相等看作同元素</li>
<li>距离定义$essinf_F$</li>
</ul>
</li>
</ul>
</li>
<li>
<p>收敛</p>
<ul>
<li>点列收敛
<ul>
<li>性质：极限唯一、有界</li>
<li>子列收敛</li>
</ul>
</li>
<li>欧式空间$\mathbb{R}^n$的收敛（如何证）
<ul>
<li>点列收敛、坐标收敛</li>
</ul>
</li>
<li>$C[a,b]$ 的收敛
<ul>
<li>按照距离导出收敛</li>
<li>某距离收敛等价函数列一致收敛</li>
</ul>
</li>
</ul>
</li>
<li>
<p>点集</p>
<ul>
<li>开球、闭球</li>
<li>开集、闭包、闭集</li>
<li>内点、内部</li>
<li>聚点、导集、孤立点</li>
<li>稠密性</li>
<li>可分性
<ul>
<li>$L^\infty[a,b]$</li>
</ul>
</li>
</ul>
</li>
<li>
<p>连续映射</p>
<ul>
<li>连续性等价条件</li>
<li>归结原则、集合描述</li>
<li>同胚、等距</li>
</ul>
</li>
<li>
<p>完备性</p>
<ul>
<li>柯西基本列</li>
<li>完备性
<ul>
<li>三条定理</li>
<li>$C[a,b]$、$l^p$、$L^\infty(F)$ 完备</li>
<li>$S$ 三角不等式及<strong>完备性证明</strong></li>
</ul>
</li>
<li>完备化
<ul>
<li>完备扩展定理</li>
<li>$C[a,b]\rightarrow L^2[a,b]$</li>
<li>$P\rightarrow C[a,b]$</li>
</ul>
</li>
</ul>
</li>
<li>
<p>稀疏集</p>
<ul>
<li>与球的的充要条件</li>
</ul>
</li>
<li>
<p>闭球套定理、第一/二类型集</p>
</li>
<li>
<p>$l_0^p$</p>
<ul>
<li>子空间、不完备、稠密</li>
</ul>
</li>
<li>
<p>$S$、$s$、$P$</p>
</li>
<li>
<p>准紧集、紧集、全有界集</p>
<ul>
<li>$\epsilon-$ 网</li>
<li>相互关系</li>
<li>紧集套</li>
<li>开覆盖</li>
<li>有限交</li>
<li>连续映射</li>
</ul>
</li>
<li>
<p>不动点定理、压缩映射</p>
</li>
<li>
<p><strong>重点梳理</strong></p>
<ul>
<li>常见度量空间，及其距离、收敛、可分性、准紧条件
<ul>
<li>$\mathbb{R}^n$ （所有分量收敛）</li>
<li>$C[a,b]$（一致收敛）、$C^k[a,b]$、$C^\infty [a,b]$</li>
<li>$l^p$、$l^\infty$（不可分）</li>
<li>$L^p$、$L^\infty$（不可分）</li>
<li>$S$（测度收敛）、$s$（按坐标收敛）</li>
</ul>
</li>
<li>重要证明
<ul>
<li>Cauchy、Holder、Minkowski、Young</li>
</ul>
</li>
<li>各类点集、球、稠密、可分</li>
<li>基本列、收敛、完备</li>
<li>连续映射</li>
<li>不动点、压缩映射</li>
</ul>
</li>
</ul>
<h2 id="ch2-巴拿赫空间希尔伯特空间" class="headerLink">
    <a href="#ch2-%e5%b7%b4%e6%8b%bf%e8%b5%ab%e7%a9%ba%e9%97%b4%e5%b8%8c%e5%b0%94%e4%bc%af%e7%89%b9%e7%a9%ba%e9%97%b4" class="header-mark"></a>Ch2. 巴拿赫空间、希尔伯特空间</h2><ul>
<li>赋范线性空间
<ul>
<li>距离空间、范数/强收敛</li>
<li>Banach</li>
<li>商空间</li>
<li>直和</li>
</ul>
</li>
<li>内积空间
<ul>
<li>导出范数
<ul>
<li>Schwarz不等式、极化恒等式</li>
<li>平行四边形公式</li>
</ul>
</li>
<li>$l^2,L^2$</li>
<li>正交、正交补、推广勾股</li>
<li>规范正交系
<ul>
<li>Bessel</li>
<li>完备、完全</li>
<li>Schmidt正交化</li>
<li>最佳逼近</li>
</ul>
</li>
</ul>
</li>
<li>Hilbert
<ul>
<li>凸集、正交分解</li>
<li>E.S.Fischer</li>
<li>Parseval</li>
<li>可分同构</li>
</ul>
</li>
</ul>
<h2 id="ch3-有界线性算子巴拿赫空间" class="headerLink">
    <a href="#ch3-%e6%9c%89%e7%95%8c%e7%ba%bf%e6%80%a7%e7%ae%97%e5%ad%90%e5%b7%b4%e6%8b%bf%e8%b5%ab%e7%a9%ba%e9%97%b4" class="header-mark"></a>Ch3. 有界线性算子：巴拿赫空间</h2><h2 id="ch4-有界线性算子希尔伯特空间" class="headerLink">
    <a href="#ch4-%e6%9c%89%e7%95%8c%e7%ba%bf%e6%80%a7%e7%ae%97%e5%ad%90%e5%b8%8c%e5%b0%94%e4%bc%af%e7%89%b9%e7%a9%ba%e9%97%b4" class="header-mark"></a>Ch4. 有界线性算子：希尔伯特空间</h2><h2 id="前辈经验" class="headerLink">
    <a href="#%e5%89%8d%e8%be%88%e7%bb%8f%e9%aa%8c" class="header-mark"></a>前辈经验</h2><p>小测：https://www.cc98.org/topic/5321722</p>]]></description>
</item><item>
    <title>复变函数</title>
    <link>https://blog.ralvines.top/fbhs/</link>
    <pubDate>Wed, 01 Mar 2023 20:20:40 &#43;0800</pubDate><author>
                        <name>Ralvine</name><uri>https://blog.ralvines.top/about.md</uri><email>ralvine@163.com</email></author><guid>https://blog.ralvines.top/fbhs/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="https://z1.ax1x.com/2023/10/23/piAW5eH.png" referrerpolicy="no-referrer">
            </div><div class="details admonition quote open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-quote-right fa-fw"></i>课程信息<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">🎓 数学科学学院<br>
🕙 2023-2024 秋冬<br>
🧑‍🏫 毕惟红<br>
📝 50%读书报告，10%考勤，10%编程，30%两次展示</div>
        </div>
    </div>
<p>!!! quote &quot;&quot;
- 🎓 数学科学学院
- 🕙 2022-2023 春夏
- 🧑‍🏫 齐治
- 📝 40%作业，60%期末</p>
<h2 id="参考" class="headerLink">
    <a href="#%e5%8f%82%e8%80%83" class="header-mark"></a>参考</h2><ul>
<li>《Complex Analysis》, Stein.</li>
<li><a href="https://classroom.zju.edu.cn/coursedetail?course_id=47986&amp;tenant_code=112" target="_blank" rel="noopener noreferrer">智云课堂回放</a></li>
<li>复变函数华师版讲义 @陆俊</li>
</ul>
<h2 id="ch1-复分析预备知识" class="headerLink">
    <a href="#ch1-%e5%a4%8d%e5%88%86%e6%9e%90%e9%a2%84%e5%a4%87%e7%9f%a5%e8%af%86" class="header-mark"></a>Ch1. 复分析预备知识</h2><h2 id="ch2-柯西定理及应用" class="headerLink">
    <a href="#ch2-%e6%9f%af%e8%a5%bf%e5%ae%9a%e7%90%86%e5%8f%8a%e5%ba%94%e7%94%a8" class="header-mark"></a>Ch2. 柯西定理及应用</h2><h2 id="ch3-亚纯函数及对数" class="headerLink">
    <a href="#ch3-%e4%ba%9a%e7%ba%af%e5%87%bd%e6%95%b0%e5%8f%8a%e5%af%b9%e6%95%b0" class="header-mark"></a>Ch3. 亚纯函数及对数</h2><h2 id="ch5-全函数" class="headerLink">
    <a href="#ch5-%e5%85%a8%e5%87%bd%e6%95%b0" class="header-mark"></a>Ch5. 全函数</h2><h2 id="ch7-留数定理" class="headerLink">
    <a href="#ch7-%e7%95%99%e6%95%b0%e5%ae%9a%e7%90%86" class="header-mark"></a>Ch7. 留数定理*</h2><h2 id="ch8-椭圆函数" class="headerLink">
    <a href="#ch8-%e6%a4%ad%e5%9c%86%e5%87%bd%e6%95%b0" class="header-mark"></a>Ch8. 椭圆函数*</h2><h2 id="ch10-theta函数" class="headerLink">
    <a href="#ch10-theta%e5%87%bd%e6%95%b0" class="header-mark"></a>Ch10. $\Theta$函数*</h2><h2 id="华师版" class="headerLink">
    <a href="#%e5%8d%8e%e5%b8%88%e7%89%88" class="header-mark"></a>华师版</h2>]]></description>
</item><item>
    <title>面向对象程序设计</title>
    <link>https://blog.ralvines.top/oop/</link>
    <pubDate>Wed, 01 Mar 2023 20:20:40 &#43;0800</pubDate><author>
                        <name>Ralvine</name><uri>https://blog.ralvines.top/about.md</uri><email>ralvine@163.com</email></author><guid>https://blog.ralvines.top/oop/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="https://z1.ax1x.com/2023/10/23/piAWIwd.png" referrerpolicy="no-referrer">
            </div><div class="details admonition quote open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-quote-right fa-fw"></i>课程信息<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">🎓 计算机科学与技术学院<br>
🕙 2022-2023 春夏<br>
🧑‍🏫 许威威<br>
📝 50%作业，50%期末</div>
        </div>
    </div>
<h2 id="介绍1" class="headerLink">
    <a href="#%e4%bb%8b%e7%bb%8d1" class="header-mark"></a>介绍<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></h2><p>Buzzwords</p>
<ul>
<li>继承</li>
<li>cohesion 凝聚</li>
<li>coupling 耦合</li>
<li>overriding</li>
<li>interface 接口</li>
<li>polymorphic 多态
<ul>
<li>polymorphic method calls</li>
</ul>
</li>
<li>matator methods</li>
<li>Encapsulation 封装</li>
</ul>
<p>C的优缺点&amp;C++新特性</p>
<h2 id="引用" class="headerLink">
    <a href="#%e5%bc%95%e7%94%a8" class="header-mark"></a>引用</h2><p>函数swap操作形参无法交换外部变量，C用指针，C++引入引用。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">int</span> <span class="n">n</span><span class="o">=</span><span class="mi">4</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">int</span><span class="o">&amp;</span> <span class="n">SetValue</span><span class="p">()</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">n</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">SetValue</span><span class="p">()</span><span class="o">=</span><span class="mi">40</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">n</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span> <span class="c1">// Output: 40.
</span></span></span></code></pre></td></tr></table>
</div>
</div><h2 id="常量" class="headerLink">
    <a href="#%e5%b8%b8%e9%87%8f" class="header-mark"></a>常量</h2><p>区别define，有类型检查。</p>
<p>常量指针，不允许通过指针修改目标内容，但可以改变指向对象。</p>
<p>在函数形参中使用，防止形参被修改</p>
<p>常量成员函数：不应修改其所作用的对象（除了静态成员变量）</p>
<p>常量对象 <code>const Sample o;</code> 不可修改对象，但是可以执行其中的常量成员函数。</p>
<p>成员函数名字参数相同，有无const的区别属于重载关系。（实例对象是否常量决定了调用哪个成员函数）</p>
<p>常引用：对象作函数参数，为了避免复制构造函数降低效率，直接用引用，而为了防止实参跟着变，采用常引用。</p>
<h2 id="动态内存分配" class="headerLink">
    <a href="#%e5%8a%a8%e6%80%81%e5%86%85%e5%ad%98%e5%88%86%e9%85%8d" class="header-mark"></a>动态内存分配</h2><p>分配变量：<code>int* P; P=new T;</code></p>
<p>T是任意类型名，相当于开辟了sizeof(T)的空间，P是指向它起始地址的指针，即T*.</p>
<p>释放：只能delete一次，对数组应为<code>delete [] p;</code></p>
<p>不delete就不会释放！</p>
<h2 id="内联函数重载和缺省参数" class="headerLink">
    <a href="#%e5%86%85%e8%81%94%e5%87%bd%e6%95%b0%e9%87%8d%e8%bd%bd%e5%92%8c%e7%bc%ba%e7%9c%81%e5%8f%82%e6%95%b0" class="header-mark"></a>内联函数、重载和缺省参数</h2><p>函数调用存在开销，调用本身耗时，内联函数在编译时直接插入函数内操作本身，但程序体积会变大。</p>
<p><code>inline int func(parameter) {}</code></p>
<p>函数名字相同但参数个数或类型不同，叫做重载。使函数命名简单，编译器自动判断调用哪个函数。二义性，调用函数的参数匹配不上。</p>
<p>缺省参数，最右边连续若干个参数可有缺省值。</p>
<p><code>void func(int x1, int x2=2, int x3=3) {}</code></p>
<h2 id="类和对象" class="headerLink">
    <a href="#%e7%b1%bb%e5%92%8c%e5%af%b9%e8%b1%a1" class="header-mark"></a>类和对象</h2><p>C语言：结构化程序设计，程序=数据结构+算法，但函数和操作的数据结构没有直接联系，规模增大后难以理解、扩充、查错。</p>
<p>C++：面向对象程序</p>
<p>指针方式：<code>ClassName* p= &amp;AClassObject</code>，用 - &gt; 指向其成员变量或函数。</p>
<p>引用方式：<code>ClassName&amp; p= AClassObject</code> 同时跟着变。</p>
<p>私有成员：缺省=private，同Class其他对象的私有成员也可访问。</p>
<p>成员函数也可重载、参数缺省。</p>
<h2 id="构造函数" class="headerLink">
    <a href="#%e6%9e%84%e9%80%a0%e5%87%bd%e6%95%b0" class="header-mark"></a>构造函数</h2><p>一个类可以有多个构造函数。</p>
<p>对象数组，注意动态分配时没定义就不初始化。</p>
<p>复制构造函数，参数必须引用<code>X::X(X&amp; x)</code>；起作用：直接<code>Complex c2(c1)</code>，或者函数参数或返回值含有该类对象；但是对象间赋值不会调用复制构造函数。</p>
<p>常量引用参数：减少开销，确保实参值不变时使用。</p>
<p>类型转换构造函数：只含一个参数。</p>
<p>析构函数：有对象数组情况下，程序结束时每个元素都会调用析构函数；临时对象和形参对象消亡都会调用。</p>
<p>局部对象：<code>{ 生命周期 }</code>，静态对象static：函数结束时不消亡。</p>
<p>不同编译器输出有所差别，有的做了优化，赋值可以不用再临时生成被复制的对象。</p>
<h2 id="this指针" class="headerLink">
    <a href="#this%e6%8c%87%e9%92%88" class="header-mark"></a>this指针</h2><p>C++编译先翻译成C时，Class变为Struct，因此需要多一个this指针指向函数作用的对象。因此可以返回对象自身。</p>
<p>静态成员函数则不可使用this指针，因为其不具体作用于某个对象。</p>
<h2 id="静态成员变量" class="headerLink">
    <a href="#%e9%9d%99%e6%80%81%e6%88%90%e5%91%98%e5%8f%98%e9%87%8f" class="header-mark"></a>静态成员变量</h2><p>静态成员为所有对象共享，总共就一份。sizeof()计算对象时不会计算其static成员变量。</p>
<p>访问方式。需要在定义类的文件中单独进行声明或初始化！</p>
<p>静态成员<strong>函数</strong>还可以直接通过整个类进行调用。</p>
<p>本质是全局变量，只是放在类中。例：方体类的实例总数。</p>
<p>⬆️缺陷，若实例对象是复制构造生成的，Total会有遗漏，特别是临时对象消亡时还会调用析构函数，因此需要单独写一个复制构造函数。</p>
<p>静态成员<strong>函数</strong>不能调用非静态的成员变量或函数。</p>
<h2 id="成员对象和封闭类" class="headerLink">
    <a href="#%e6%88%90%e5%91%98%e5%af%b9%e8%b1%a1%e5%92%8c%e5%b0%81%e9%97%ad%e7%b1%bb" class="header-mark"></a>成员对象和封闭类</h2><p>Class中有成员变量为其他Class类型，即称其为成员对象。例如Class Car下有成员变量Engine，属于Engine类。</p>
<p>初始化列表：构造函数后直接赋值。</p>
<p>先执行封闭类下所有对象成员构造函数，再执行封闭类构造函数；析构时顺序相反。</p>
<h2 id="友元" class="headerLink">
    <a href="#%e5%8f%8b%e5%85%83" class="header-mark"></a>友元</h2><p>友元类，关系不能传递和继承。</p>
<h2 id="运算符重载" class="headerLink">
    <a href="#%e8%bf%90%e7%ae%97%e7%ac%a6%e9%87%8d%e8%bd%bd" class="header-mark"></a>运算符重载</h2><p>根据参数数目决定重载为成员函数或普通函数</p>
<p>赋值运算符的重载：以string为例，需要防止指向同一块内存。</p>
<p>此时返回对象需要引用，如<code>String&amp;</code>：应当保留运算符原本特性，使得允许a=b=c和(a=b)=c.</p>
<p>还需要防止s=s.</p>
<p>还需要为其写单独的复制构造函数。</p>
<p>若声明时直接赋值，属于调用构造函数。</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>智云课堂回放 <a href="https://classroom.zju.edu.cn/coursedetail?course_id=50910&amp;tenant_code=112" target="_blank" rel="noopener noreferrer">https://classroom.zju.edu.cn/coursedetail?course_id=50910&tenant_code=112</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>]]></description>
</item><item>
    <title>偏微分方程</title>
    <link>https://blog.ralvines.top/pde/</link>
    <pubDate>Wed, 01 Mar 2023 20:20:40 &#43;0800</pubDate><author>
                        <name>Ralvine</name><uri>https://blog.ralvines.top/about.md</uri><email>ralvine@163.com</email></author><guid>https://blog.ralvines.top/pde/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="https://z1.ax1x.com/2023/10/23/piAW5eH.png" referrerpolicy="no-referrer">
            </div><div class="details admonition quote open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-quote-right fa-fw"></i>课程信息<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">🎓 计算机科学与技术学院<br>
🕙 2022-2023 春夏<br>
🧑‍🏫 许威威<br>
📝 50%作业，50%期末</div>
        </div>
    </div>
<p>!!! quote &quot;&quot;
- 🎓 数学科学学院
- 🕙 2021-2022 春夏
- 🧑‍🏫 鲁汪涛
- 📝 作业，小测，期末考试</p>
<h2 id="参考" class="headerLink">
    <a href="#%e5%8f%82%e8%80%83" class="header-mark"></a>参考</h2><h2 id="ch1-引言" class="headerLink">
    <a href="#ch1-%e5%bc%95%e8%a8%80" class="header-mark"></a>Ch.1 引言</h2><h3 id="1-发展史" class="headerLink">
    <a href="#1-%e5%8f%91%e5%b1%95%e5%8f%b2" class="header-mark"></a>1. 发展史</h3><blockquote>
<p>17 - 微积分 Newton &amp; Lebnitz</p>
<p>18 - Euler &amp; Bernoulli &amp; Lagrange &amp; Laplace &amp; Poisson</p>
<p>19 - pde应用 Fourier &amp; Green &amp; Cauchy &amp; Hadamard</p>
<p>20 - 复杂理论</p>
<p>21 - 计算机数值分析 &amp; 微分方程数值解</p>
</blockquote>
<h3 id="2-基本定义" class="headerLink">
    <a href="#2-%e5%9f%ba%e6%9c%ac%e5%ae%9a%e4%b9%89" class="header-mark"></a>2. 基本定义</h3><h4 id="21-概念" class="headerLink">
    <a href="#21-%e6%a6%82%e5%bf%b5" class="header-mark"></a>2.1 概念</h4><ul>
<li><strong>向量：</strong>$x=(x_1,x_2,\cdots,x_n)\in \mathbb{R}^n,x\in \Omega$ 开区域</li>
<li><strong>函数：</strong>$u:\Omega\rightarrow\mathbb{R}$  偏导$\displaystyle\frac{\partial u}{\partial x_1}=\partial_{x_{1}}u=\partial_{1}u$</li>
<li><strong>梯度：</strong>$grad/\nabla/Du=(\partial_{1}u,\partial_{2}u,\cdots,\partial_{n}u)$</li>
<li><strong>散度：</strong>$\vec{F}=(F_1,F_2,\cdots,F_n),\Omega\rightarrow \mathbb{R}^n\Rightarrow div\vec{F}=\displaystyle\sum\limits_{i=1}^n\frac{\partial F_i}{\partial x_i}$</li>
<li><strong>Hessian矩阵：</strong>$D^2u=\begin{pmatrix}\displaystyle\frac{\partial^2u}{\partial x_1^2}&amp;\displaystyle\frac{\partial^2 u}{\partial x_1x_2}&amp;\cdots&amp;\displaystyle\frac{\partial^2u}{\partial x_1x_n}\\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\displaystyle\frac{\partial^2u}{\partial x_nx_1}&amp;\displaystyle\frac{\partial^2u}{\partial x_nx_2}&amp;\cdots&amp;\displaystyle\frac{\partial^2u}{\partial x_n^2}\end{pmatrix}$</li>
<li><strong>Laplace算子：</strong> $\Delta u=tr(D^2u)$=$\displaystyle\sum\limits_{i=1}^n\frac{\partial ^2u}{\partial x_i^2}$=$div$($Du$)  散度的梯度</li>
<li><strong>所有k阶偏导：</strong>$D^ku=\displaystyle\frac{\partial^ku}{\partial x_{i1}\partial x_{i2}\cdots\partial x_{ik}}\in\mathbb{R}^{n^k},n^k个$</li>
</ul>
<p>$|D^ku|=(\sum\limits_{i1=1}^n\sum\limits_{i2=1}^n\cdots\sum\limits_{ik=1}^n|\partial_{x1}\partial_{x2}\cdots\partial_{xk}u|)^{1/2}$</p>
<ul>
<li><strong>多重指标：</strong>$\alpha=(\alpha_1,\alpha_2,\cdots,\alpha_n), 阶|\alpha|=\alpha_1+\alpha_2+\cdots+\alpha_n$ 去重</li>
</ul>
<p>$D^\alpha u=\partial_{x1}^{\alpha1}\partial_{x1}^{\alpha2}\cdots\partial_{x1}^{\alpha n}\Rightarrow|D^ku|=(\sum\limits_{|\alpha|=k}|D^\alpha u|^2)^{1/2}$</p>
<ul>
<li><strong>偏微分方程：</strong></li>
</ul>
<p>$F(D^ku(x),D^{k-1}u(x),\cdots,Du(x),u(x),x)=0, x\in\Omega.$ k阶</p>
<p>$\displaystyle\left{\begin{array}{l}
F:\mathbb{R}^{n^k}\times\mathbb{R}^{n^{k-1}}\times\cdots\times\mathbb{R}^{n}\times\mathbb{R}\times\Omega\rightarrow\mathbb{R}.（已知）\
u:\Omega\rightarrow\mathbb{R}.（未知）\
\end{array}\right.$</p>
<h4 id="22-线性空间" class="headerLink">
    <a href="#22-%e7%ba%bf%e6%80%a7%e7%a9%ba%e9%97%b4" class="header-mark"></a>2.2 线性空间</h4><ul>
<li>
<p><strong>函数：</strong>$u\rightarrow C(\Omega), ||u||<em>{C(\Omega)}=\sup\limits</em>{x\in\Omega}|u(x)|.$</p>
</li>
<li>
<p><strong>k次连续可微函数：</strong>$||u||<em>{C^k(\Omega)}=\sup\limits</em>{x\in\Omega}|u(x)|+\displaystyle\sum\limits_{|\alpha|=1}^2\sup\limits_{x\in\Omega}|D^\alpha u(x)|.$</p>
</li>
<li>
<p><strong>支集：</strong>$spt\space u=\overline{{ x\in\Omega|u(x)\neq0}}.$所有满足$u(x)\neq0$点集在$\Omega$上的闭包</p>
</li>
<li>
<p>$C_0^k$ 具有紧支集的函数类；$C^\infty(\Omega)=\bigcap\limits_{k=1}^\infty C^k(\Omega)$任意阶偏导存在且连续的函数类</p>
</li>
</ul>
<h4 id="23-解的光滑性" class="headerLink">
    <a href="#23-%e8%a7%a3%e7%9a%84%e5%85%89%e6%bb%91%e6%80%a7" class="header-mark"></a>2.3 解的光滑性</h4><p>解析 $\rightarrow$ 无穷光滑 $\rightarrow$ k次连续可微(古典解) $\rightarrow$ 弱解(广义解)</p>
<h4 id="24-分类" class="headerLink">
    <a href="#24-%e5%88%86%e7%b1%bb" class="header-mark"></a>2.4 分类</h4><ul>
<li>
<p><strong>线性：</strong>$\displaystyle\sum\limits_{|\alpha|\leq k}a_{\alpha}(x)D^{\alpha}u=f(x)$</p>
</li>
<li>
<p><strong>半线性：</strong>$\displaystyle\sum\limits_{|\alpha|=k}a_{\alpha}(x)D^{\alpha}u=f[D^{k-1}u(x),\cdots,Du(x),u(x),x]$</p>
</li>
<li>
<p><strong>拟线性：</strong>$\displaystyle\sum\limits_{|\alpha|=k}a_{\alpha}[D^{k-1}u(x),\cdots,Du(x),u(x),x]D^{\alpha}u=f[D^{k-1}u(x),\cdots,Du(x),u(x),x]$</p>
</li>
<li>
<p>**完全非线性：**非线性依赖$D^ku$</p>
</li>
</ul>
<h3 id="3-实例" class="headerLink">
    <a href="#3-%e5%ae%9e%e4%be%8b" class="header-mark"></a>3 实例</h3><ol>
<li><strong>Laplace方程：</strong>$\Delta u=0$</li>
<li><strong>特征值方程：</strong>$\Delta u+\lambda u=0$</li>
<li><strong>热方程：</strong>$u_t-a^2\Delta u=0(a&gt;0)$</li>
<li>&hellip;</li>
</ol>
<h3 id="4-椭圆型" class="headerLink">
    <a href="#4-%e6%a4%ad%e5%9c%86%e5%9e%8b" class="header-mark"></a>4 椭圆型&amp;</h3><h3 id="5-适定性" class="headerLink">
    <a href="#5-%e9%80%82%e5%ae%9a%e6%80%a7" class="header-mark"></a>5 适定性</h3><h4 id="51-定义" class="headerLink">
    <a href="#51-%e5%ae%9a%e4%b9%89" class="header-mark"></a>5.1 定义</h4><ul>
<li>
<p>**定解问题：**PDE+条件</p>
</li>
<li>
<p>**适定：**解存在、唯一、连续依赖已知函数</p>
</li>
<li>
<p>**形式解：**对实际问题假设解的光滑性以求出表达式（先验估计）</p>
</li>
<li>
<p>$\Omega$ - 开域、$\overline\Omega$ - 闭包、$\partial\Omega$ - 边界</p>
<p>$\mathbb{R}_+^n={x=(x_1,\cdots,x_n)\in\mathbb{R}^n|x_n&gt;0}$ 上半空间</p>
<p>$\mathbb{R}<em>+^1=\mathbb{R}</em>+,\space\mathbb{R}<em>+^{n+1}=\mathbb{R}</em>+^n\times\mathbb{R}_+$</p>
</li>
<li>
<p><strong>闭球：</strong>$B(x,r),\space 体积\space\alpha(n)r^n=$</p>
<p>…………………………</p>
</li>
</ul>
<h4 id="52-定理" class="headerLink">
    <a href="#52-%e5%ae%9a%e7%90%86" class="header-mark"></a>5.2 定理</h4><ul>
<li>
<p><strong>Green 公式：</strong></p>
<p>…………………………</p>
</li>
</ul>
<h2 id="ch2-位势方程" class="headerLink">
    <a href="#ch2-%e4%bd%8d%e5%8a%bf%e6%96%b9%e7%a8%8b" class="header-mark"></a>Ch.2 位势方程</h2><h3 id="1-possion方程" class="headerLink">
    <a href="#1-possion%e6%96%b9%e7%a8%8b" class="header-mark"></a>1 Possion方程</h3><p>$-\Delta u=f(x)$</p>
<h3 id="2-调和函数" class="headerLink">
    <a href="#2-%e8%b0%83%e5%92%8c%e5%87%bd%e6%95%b0" class="header-mark"></a>2 调和函数</h3><p>$\displaystyle\int_a^b\hspace{-1.5em}-\ f(x), \mathrm{d}x$</p>
<h2 id="ch3-热方程" class="headerLink">
    <a href="#ch3-%e7%83%ad%e6%96%b9%e7%a8%8b" class="header-mark"></a>Ch.3 热方程</h2><h3 id="1-基本定义" class="headerLink">
    <a href="#1-%e5%9f%ba%e6%9c%ac%e5%ae%9a%e4%b9%89" class="header-mark"></a>1 基本定义</h3><h4 id="11-热方程" class="headerLink">
    <a href="#11-%e7%83%ad%e6%96%b9%e7%a8%8b" class="header-mark"></a>1.1 热方程</h4><ul>
<li><strong>基本形式：</strong>$u_t-a^2\Delta u=f,\space u(x,t),\space f(x,t),\space x\in\Omega\subset\mathbb{R^n},t&gt;0$</li>
<li><strong>推导</strong></li>
<li>**反应扩散方程：**反应项、扩散项</li>
</ul>
<h4 id="12-概念" class="headerLink">
    <a href="#12-%e6%a6%82%e5%bf%b5" class="header-mark"></a>1.2 概念</h4><ul>
<li>
<p><strong>定解问题：</strong></p>
<ul>
<li>
<p><strong>定解条件</strong></p>
<ul>
<li>
<p><strong>初始条件：</strong>$u(x,0)=\varphi (x)$</p>
</li>
<li>
<p>**边值条件：**边界分布或外围介质影响（$x\in\partial\Omega,t\ge0$）</p>
<p>$u(x,t)=g(x,t)$. $g=const$ 恒温</p>
<p>$k\frac{\partial}{\partial\displaystyle\vec{n}}u(x,t)=g(x,t)$. $g\ge0$ 热量流入；$g\equiv0$ 绝热</p>
</li>
</ul>
</li>
<li>
<p><strong>偏微分方程</strong></p>
</li>
</ul>
</li>
<li>
<p>**函数集：**所有$Q$内关于$x$二阶偏导连续，关于$t$一阶偏导连续函数</p>
<p>$C^{2,1}(Q)={u\in C(Q)|u_t,u_{xi},u_{xixj}\in C(Q);i,j=1,\cdots,n}$</p>
</li>
<li>
<p>**古典解：**热方程在上述集中的解</p>
</li>
<li>
<p>$C^{1,0}(Q)$</p>
</li>
</ul>
<h3 id="2-初值问题" class="headerLink">
    <a href="#2-%e5%88%9d%e5%80%bc%e9%97%ae%e9%a2%98" class="header-mark"></a>2 初值问题</h3><h4 id="21-fourier" class="headerLink">
    <a href="#21-fourier" class="header-mark"></a>2.1 Fourier</h4><ul>
<li>
<p><strong>Fourier 级数展开</strong></p>
<p>$f(x)\in C^1(\mathbb{R}),\space\forall l&gt;0,\space x\in(-l,l)$</p>
<p>$f(x)=\displaystyle\frac{a_0}{2}+\displaystyle\sum\limits_{k=1}^\infty \big (a_k\cos \displaystyle\frac{k\pi}{l}x+b_k\sin\displaystyle\frac{k\pi}{l}x\big )$</p>
</li>
<li>
<p>**Fourier 积分：**级数极限</p>
</li>
</ul>
<h4 id="22-一维热方程初值问题" class="headerLink">
    <a href="#22-%e4%b8%80%e7%bb%b4%e7%83%ad%e6%96%b9%e7%a8%8b%e5%88%9d%e5%80%bc%e9%97%ae%e9%a2%98" class="header-mark"></a>2.2 一维热方程初值问题</h4><p>$$
\displaystyle\left{\begin{array}{l}
\displaystyle\frac{\partial{u}}{\partial t}-a^2\displaystyle\frac{\partial^2u}{\partial x^2}=f(x,t), &amp; (x,t)\in\mathbb{R}\times\mathbb{R}_+\
u(x,0)=\varphi(x), &amp; x\in\mathbb
{R}\
\end{array}\right.
$$</p>
<p>!!! quote &quot;&quot;
- 🎓 数学科学学院
- 🕙 2022-2023 秋冬
- 🧑‍🏫 孔德兴
- 📝 作业，考试</p>
<h2 id="参考-1" class="headerLink">
    <a href="#%e5%8f%82%e8%80%83-1" class="header-mark"></a>参考</h2><ul>
<li>《偏微分方程》孔德兴</li>
</ul>
<h2 id="ch1-绪论" class="headerLink">
    <a href="#ch1-%e7%bb%aa%e8%ae%ba" class="header-mark"></a>Ch1. 绪论</h2><h2 id="ch2-一阶方程" class="headerLink">
    <a href="#ch2-%e4%b8%80%e9%98%b6%e6%96%b9%e7%a8%8b" class="header-mark"></a>Ch2. 一阶方程</h2><ul>
<li>线性方程</li>
<li>拟线性方程</li>
<li>偏微分方程组</li>
</ul>
<h2 id="ch3-双元二阶方程" class="headerLink">
    <a href="#ch3-%e5%8f%8c%e5%85%83%e4%ba%8c%e9%98%b6%e6%96%b9%e7%a8%8b" class="header-mark"></a>Ch3. 双元二阶方程</h2><h2 id="ch4-波动方程" class="headerLink">
    <a href="#ch4-%e6%b3%a2%e5%8a%a8%e6%96%b9%e7%a8%8b" class="header-mark"></a>Ch4. 波动方程</h2><ul>
<li>一维
<ul>
<li>导出、定解条件</li>
<li>柯西问题</li>
<li>初边值问题
<ul>
<li>分离变量法</li>
</ul>
</li>
</ul>
</li>
<li>高维
<ul>
<li>球平均法</li>
</ul>
</li>
<li>传播</li>
<li>能量不等式</li>
</ul>
<h2 id="ch5-热传导方程" class="headerLink">
    <a href="#ch5-%e7%83%ad%e4%bc%a0%e5%af%bc%e6%96%b9%e7%a8%8b" class="header-mark"></a>Ch5. 热传导方程</h2><ul>
<li>导出、定解条件</li>
<li>柯西问题
<ul>
<li>傅立叶变换法</li>
</ul>
</li>
<li>初边值问题</li>
<li>极值原理</li>
</ul>
<h2 id="ch6-laplace方程" class="headerLink">
    <a href="#ch6-laplace%e6%96%b9%e7%a8%8b" class="header-mark"></a>Ch6. Laplace方程</h2><ul>
<li>导出、定解条件</li>
<li>变分法</li>
<li>调和函数
<ul>
<li>格林公式</li>
<li>极值原理</li>
</ul>
</li>
<li>格林函数
-镜像法</li>
<li>强极值原理</li>
</ul>]]></description>
</item><item>
    <title>实变函数</title>
    <link>https://blog.ralvines.top/sbhs/</link>
    <pubDate>Wed, 01 Mar 2023 20:20:40 &#43;0800</pubDate><author>
                        <name>Ralvine</name><uri>https://blog.ralvines.top/about.md</uri><email>ralvine@163.com</email></author><guid>https://blog.ralvines.top/sbhs/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="https://z1.ax1x.com/2023/10/23/piAW5eH.png" referrerpolicy="no-referrer">
            </div><div class="details admonition quote open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-quote-right fa-fw"></i>课程信息<i class="details-icon fas fa-angle-right fa-fw"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">🎓 数学科学学院<br>
🕙 2022-2023 春夏<br>
🧑‍🏫 贾厚玉<br>
📝 20%小测，20%作业，60%期末</div>
        </div>
    </div>
<h2 id="参考" class="headerLink">
    <a href="#%e5%8f%82%e8%80%83" class="header-mark"></a>参考</h2><ul>
<li>《实变函数》，周性伟</li>
<li>PPT
<ul>
<li>Ch1.1</li>
<li>Ch1.2</li>
<li>Ch3</li>
<li>Ch4</li>
<li>Ch5</li>
<li>Ch6</li>
</ul>
</li>
<li><a href="https://classroom.zju.edu.cn/coursedetail?course_id=51173&amp;tenant_code=112" target="_blank" rel="noopener noreferrer"><em>智云课堂回放</em></a></li>
<li><a href="https://www.bilibili.com/video/BV1MX4y1w7fm/?spm_id_from=333.788&amp;vd_source=e81e93bc6892fd0d7e19b265d26a2b3a" target="_blank" rel="noopener noreferrer">实变函数习题十讲</a></li>
<li><a href="https://www.bilibili.com/video/BV1MX4y1w7fm/?spm_id_from=333.788&amp;vd_source=e81e93bc6892fd0d7e19b265d26a2b3a" target="_blank" rel="noopener noreferrer"></a></li>
</ul>
<h2 id="ch1-集合" class="headerLink">
    <a href="#ch1-%e9%9b%86%e5%90%88" class="header-mark"></a>Ch1. 集合</h2><ul>
<li>三次完备化
<ul>
<li>有理数&amp;实数（极限封闭）</li>
<li>黎曼几分&amp;勒贝格积分</li>
<li>广义函数（Dirac）</li>
</ul>
</li>
<li>集合运算
<ul>
<li>表示、集族</li>
<li>幂集</li>
<li>交、并、差、对称差、无穷、间断点集</li>
<li>DeMorgan</li>
</ul>
</li>
<li>集合序列、极限
<ul>
<li>单调集列</li>
<li>上下限集、上下极限</li>
<li>笛卡尔乘积、性质</li>
</ul>
</li>
<li>映射
<ul>
<li>映射（单、满、逆）、像/原像（性质）、复合</li>
</ul>
</li>
<li>特征函数</li>
<li>集合等价、基数
<ul>
<li>集合对等</li>
<li>基数（势）</li>
<li>有限/可数集
<ul>
<li>[0,1]不可数</li>
<li>A~A$\cup$B</li>
</ul>
</li>
<li>连续统势
<ul>
<li>n元数列全体</li>
<li>可数集子集全体</li>
<li>至多可数直积全体</li>
</ul>
</li>
<li>基数比较
<ul>
<li>$A_2\subset A_1\subset A_0,A_0$~$A_2\Rightarrow A_0$~$A_1$</li>
<li>Banach分解、分离集</li>
<li>Cantor-Bernstein定理（真子集对等）</li>
</ul>
</li>
</ul>
</li>
<li>$\mathbb{R}^n$
<ul>
<li>笛卡尔乘积、加法、数乘、内积、模、距离</li>
<li>性质（交换、柯西不等式、系数、三角不等式）</li>
<li>邻域</li>
<li>极限描述（距离、邻域、$\epsilon-N$、分量）</li>
<li>点集
<ul>
<li>内点、内域</li>
<li>外点、外域</li>
<li>边界点</li>
<li>聚点、导集</li>
<li>闭包</li>
<li>孤立点、孤立集</li>
<li>离散集</li>
<li>稠密集、无处稠密集、疏朗集</li>
<li>开集、闭集</li>
<li>自密集、完备集</li>
</ul>
</li>
<li>一些性质、Bolzano-Weierstrass定理</li>
<li>开集构造定理</li>
<li>Cantor完备集
<ul>
<li>性质（无内点、连续统势c、稠子集、开区间长度和）</li>
<li>Cantor函数</li>
</ul>
</li>
<li>长方体（矩体）、方体</li>
</ul>
</li>
<li>连续映射
<ul>
<li>距离函数、性质</li>
<li>开覆盖、紧集
<ul>
<li>充要条件：有界闭集</li>
</ul>
</li>
<li>连续延拓定理</li>
<li>连续函数的集合特征</li>
</ul>
</li>
</ul>
<h2 id="ch2-l可测集" class="headerLink">
    <a href="#ch2-l%e5%8f%af%e6%b5%8b%e9%9b%86" class="header-mark"></a>Ch2. L可测集</h2><ul>
<li>外测度
<ul>
<li>L覆盖（开区间、可有限）</li>
<li>集合函数</li>
<li>单点集（利用数列）</li>
<li>非负、单调、次可数可加、平移不变</li>
<li>区间</li>
<li>$[0,1]$Cantor集</li>
<li>$m^*_\delta (E)$</li>
<li>不相交可加性、介值</li>
</ul>
</li>
<li>可测集$\mathcal{M}$
<ul>
<li>卡氏条件</li>
<li>充要条件</li>
</ul>
</li>
<li>测度
<ul>
<li>零测集（单点、有理数、任意子集）、可测</li>
<li>区间可测</li>
<li>性质（空、交并差、可数交并、可数可加）</li>
<li>单调可测集列</li>
<li>平移不变性</li>
<li>不可测集</li>
<li>Borel集</li>
<li>$G_\delta, F_\sigma$</li>
<li>可测集构造（开/闭集逼近）、等价命题</li>
<li>可测集特征</li>
</ul>
</li>
<li>代数、$\sigma$代数
<ul>
<li>定义</li>
<li>Borel可测、非Borel可测、关系</li>
</ul>
</li>
<li>$\mathbb{R}^n$可测集
<ul>
<li>直积可测性问题</li>
</ul>
</li>
</ul>
<h2 id="ch3-可测函数" class="headerLink">
    <a href="#ch3-%e5%8f%af%e6%b5%8b%e5%87%bd%e6%95%b0" class="header-mark"></a>Ch3. 可测函数</h2><ul>
<li>定义
<ul>
<li>广义实数</li>
<li>可测函数</li>
<li>特征函数可测</li>
<li>稠密和可测例</li>
</ul>
</li>
<li>性质
<ul>
<li>运算</li>
<li>几乎处处</li>
<li>局部有界</li>
</ul>
</li>
<li>连续函数逼近
<ul>
<li>简单函数</li>
<li>支集</li>
</ul>
</li>
<li>测度收敛
<ul>
<li>逐点收敛</li>
<li>一致收敛</li>
<li>几乎处处收敛
<ul>
<li>Egoroff</li>
</ul>
</li>
<li>依测度收敛
<ul>
<li>依测度基本列</li>
<li>Riesz</li>
<li>Lusin、逆命题</li>
</ul>
</li>
<li>连续扩张定理</li>
<li>连续逼近、Frechet</li>
</ul>
</li>
</ul>
<h2 id="ch4-l积分" class="headerLink">
    <a href="#ch4-l%e7%a7%af%e5%88%86" class="header-mark"></a>Ch4. L积分</h2><ul>
<li>非负简单函数
<ul>
<li>分划</li>
<li>L积分、性质</li>
</ul>
</li>
<li>非负可测函数
<ul>
<li>等价定义</li>
<li>性质</li>
<li>Chebyshev不等式</li>
<li>几乎处处有限</li>
<li>积分为0条件</li>
<li>绝对连续性</li>
<li>分布函数</li>
<li>Levi（非负渐升列）</li>
<li>逐项积分</li>
<li>Fatou</li>
</ul>
</li>
<li>一般可测函数
<ul>
<li>有界、控制函数</li>
<li>性质</li>
<li>绝对连续性</li>
<li>LDCT</li>
<li>有界收敛</li>
<li>逐项积分</li>
<li>分片积分</li>
<li>含参</li>
</ul>
</li>
<li>R积分与L积分
<ul>
<li>广义R</li>
<li>重积分、累次积分</li>
<li>Tonelli</li>
<li>分布函数表达</li>
</ul>
</li>
<li>Fubini</li>
<li>可积与连续
<ul>
<li>卷积</li>
</ul>
</li>
</ul>
<h2 id="ch5-l微分" class="headerLink">
    <a href="#ch5-l%e5%be%ae%e5%88%86" class="header-mark"></a>Ch5. L微分</h2><ul>
<li>单调可微
<ul>
<li>Vitali覆盖</li>
<li>覆盖定理</li>
<li>单调微分定理</li>
<li>Dini微商</li>
<li>单调可微性</li>
<li>逐项微分</li>
</ul>
</li>
<li>有界变差</li>
<li>不定积分的微分</li>
<li>绝对连续函数、微积分基本定理</li>
<li>密度、全密点、近似连续点</li>
</ul>
<h2 id="ch6-lp空间" class="headerLink">
    <a href="#ch6-lp%e7%a9%ba%e9%97%b4" class="header-mark"></a>Ch6. $L^p$空间</h2><ul>
<li>定义
<ul>
<li>本性有界（上界、上确界）</li>
<li>$L^\infty$、$||\ ||_\infty$</li>
<li>线性空间</li>
</ul>
</li>
<li>Holder不等式
<ul>
<li>共轭指标</li>
<li>Young不等式</li>
</ul>
</li>
<li>Minkowski不等式</li>
<li>完备距离空间</li>
<li>极限
<ul>
<li>收敛列</li>
<li>柯西基本列</li>
<li>稠密、可分</li>
</ul>
</li>
</ul>
<h2 id="前辈经验" class="headerLink">
    <a href="#%e5%89%8d%e8%be%88%e7%bb%8f%e9%aa%8c" class="header-mark"></a>前辈经验</h2><blockquote>
<p>以下基于个人学习经历与其他情况写一些关于实变函数的学习建议（普适）零.实变函数是近代分析学的起点，起着“地基”的作用。首先明确两个问题，一是这门课所要研究的数学对象，二是为了研究这个数学对象我们引进了哪些数学工具。在数学分析中我们的研究对象是一个单独的函数，所使用的数学工具是微分、积分、极限。实变函数课提出了一个全新的观点：我们不再单独研究一个函数，而是把一些函数打包成一个集合，组成“函数空间”这样一个整体。我们的研究对象就是各种“函数空间”，所使用的工具是“<strong>测度”与“积分</strong>”。分析中的一个重要支柱是利用“函数空间”去解“各种偏微分方程”，这门课是分析学的一个重要基础</p>
<p><strong>一.参考书：</strong></p>
<p>1.学院用的教材是周性伟先生的教材（与同济大学相同），但习题较困难，建议配上周民强的实变函数论，尤其强调例题（大部分与教材中类似或重合）</p>
<p>2.英文参考书：Folland（实分析教材，写的很好，但对初学者阅读难度较大）、Stein（主线清晰，但部分重要结论在习题中，正文直接引用）</p>
<p><strong>二.这门课的核心内容是：</strong></p>
<p>（1）测度论 （2）积分论 （3）利用测度与积分去研究函数空间（主要研究Lp空间与L2空间）</p>
<p>注记1：教材会在最开始花笔墨讲解集合论的东西，引入集合论的原因是我们在这门课的学习中会遇到不可数集，进行不可数的运算，为了避免逻辑上的自相矛盾，我们需要引入选择公理。事实上如果你承认一些基本事实，那么即使不学这部分的内容也无伤大雅。但是对于一些有精神洁癖的同学，凡事都想刨根问底，那么跳过这部分直接学测度论可能就会有一些难受，但是，切记<strong>集合论不是这门课的重点！</strong></p>
<p>注记2：一个很重要的观点：<strong>集合是特殊的函数，测度是特殊的积分</strong></p>
<p>1.**测度：**如何测量一个集合的“度”，这个“度”是“长度”、“面积”、“体积”等概念的推广。教材是从欧式空间的Lebesgue测度讲起，它是欧式空间上最自然最canonical的测度，是最符合我们直觉的测度 它的构造测度的步骤是：“（长方体的）体积-&gt;（任意集合的）外测度/内测度-&gt;（Lebesgue可测集的）Lebesgue测度” 在对一个具体的空间定义好了什么是测度后，我们很自然地要考虑更加整体的性质，即把所有带有测度结构的空间放到一起研究。注意到可测函数的复合依然是可测函数，这是一个重要的性质，我们很多年后也许会忘记这门课具体内容，但应该会记得Littleword三原理。这是一种哲学上的观点：可测集差不多是开集，可测函数差不多是连续函数，依测度收敛差不多是一致收敛。如果我们用范畴的观点去看，Littleword三原理其实就是在比较拓扑范畴与测度范畴的关系。作为范畴中的对象，拓扑结构由开集刻画，测度结构由可测集刻画，Caratheodory定理描述了这两个结构的关系。作为范畴中的态射，拓扑范畴的态射是连续函数，测度范畴的态射是可测函数，Lusin定理描述了这两个态射的关系。这两个范畴中又都有极限结构，Egorov定理描述了这两种收敛的关系</p>
<p>2.**.积分：**对比较特殊的欧式空间，我们会学习Lebesgue积分，它是数学分析中黎曼积分的推广。这里大家要理解：数学分析中学的黎曼积分有哪些不足，Lebesgue积分如何弥补了这些不足；黎曼积分中的许多定理如何推广到Lebesgue积分上去 如何从测度定义积分，是积分论要掌握的核心知识，集合对应于特征函数，所以我们可以定义特征函数的积分，再由sigma可加性，我们可以定义简单函数的积分，再利用Levi单调收敛定理，我们进而可以定义非负可测函数的积分，最后利用绝对值可积，我们定义可测函数的积分。值得注意的是，这不仅做到了“把测度的定义推广到积分的定义”，同时保留了很多良好的性质与定理</p>
<p>3.<strong>Lebesgue积分VSRiemann积分：</strong> 一个自然的问题：黎曼积分中的一些定理和性质是不是在Lebesgue积分的框架下依然成立呢？我们在数学分析中学过以下四个理论：牛顿莱布尼兹定理、局部积分公式、中值定理、链式法则。在推广到Lebesgue积分论的过程中，最重要的一定要知道，我们是在什么框架下推广的！</p>
<p>4.计算题 这门课的计算题大致有：计算Lebesgue积分、计算有界变差。计算Lebesgue积分的常见方法有换元法、局部积分公式、中值定理、单调收敛定理、Lebesgue控制收敛定理。计算有界变差的常见方法有导函数的黎曼积分、计数函数的积分。每种计算的每种方法都可以在书上找到课后习题，这部分的内容就是靠做题练的，<strong>没有捷径</strong>。</p>
</blockquote>
<h2 id="参考书目" class="headerLink">
    <a href="#%e5%8f%82%e8%80%83%e4%b9%a6%e7%9b%ae" class="header-mark"></a>参考书目</h2><ul>
<li>周性伟</li>
<li>周民强</li>
<li>郑维声、王声望</li>
</ul>]]></description>
</item></channel>
</rss>
